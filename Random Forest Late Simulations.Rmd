---
title: "Random Forest Late Simulations"
author: "Ed Jee"
date: "January 27, 2019"
output:
    html_document:
      code_folding: show
      highlight: tango
      theme: readable
      toc: yes
      toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```



This document explores Causal Random Forest's ability to detect heterogeneous treatment effects with different signs - i.e. the ability to detect defiers in a first stage regression equation.

We start by defining some simulation functions that will be useful. All the R code can be hidden using the top right dropdown button if you wish but not every plot is explained so sometimes the code helps.
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(grf)

create_binary_complier_defier <- function(n, beta_complier, beta_defier, prop_defier){
  ATE <- beta_defier * prop_defier + (1 - prop_defier) * beta_complier
  if (ATE < 0){
    stop("Average Treatment Effect less than 0")
  }
  defier_status <- rbinom(n = n, size = 1, prob = prop_defier)
  tau <- beta_defier * defier_status + beta_complier * (1 - defier_status)
  i <- 0
  while (mean(tau) < 0){
    i <- i + 1
    if (i == 10){
      warning("Sample ATE less than 0")
      break
    }
    defier_status <- rbinom(n = n, size = 1, prob = prop_defier)
    tau <- beta_defier * defier_status + beta_complier * (1 - defier_status)
  }
  return(tau)
}

create_covariate_data <- function(n, n_variables){
  X <- matrix(rnorm(n*n_variables), n, n_variables)
  return(X)
}


create_likelihood <- function(covariates, instrument, tau){
  n <- length(instrument)
  Y <- covariates[, 1] * 0.5 + (covariates[, 2]^2) * 0.4 + -1*covariates[, 3] + instrument*tau + rnorm(n)
  return(Y)
}

create_simulated_data <- function(n = 1000, n_variables = 5, instrument, tau){
  X <- create_covariate_data(n = n, n_variables = n_variables)
  Y <- create_likelihood(covariates = X, instrument = instrument, tau = tau)
  return(list("X" = X, "Y" = Y, "instrument" = instrument))
}


```



These functions deal with the actual estimation and post-processing of models:
```{r}

estimate_heterogeneous_tau <- function(X, Y, Z, tree_number = 4000, num.threads = NULL){
  rf <- causal_forest(X = X, Y = Y, W = Z, num.trees = tree_number, num.threads = num.threads)
  tau_hat_oob <- predict(rf, estimate.variance = TRUE)
  return(tau_hat_oob)
}

perform_inference_mono <- function(tau_hat_data, alpha, n_covariates){
  n <- nrow(tau_hat_data)
  critical_value <- qt(1 - alpha, df = n - n_covariates - 2, lower.tail = FALSE)
  tau_transformed <- tau_hat_data %>% 
    mutate(t_stat = predictions / sqrt(variance.estimates),
           reject_H0 = ifelse(t_stat < critical_value, 1, 0))
  return(tau_transformed)
}


violates_monotonicity_check <- function(tau_hat_t_stat){
  violations <- tau_hat_t_stat %>% 
    filter(reject_H0 == 1)
  if (nrow(violations) > 0){
    return(TRUE)
  } else {
    return(FALSE)
  }
}

minimum_tau_hat <- function(tau_hat_t_stat){
  min_tau_hat <- min(tau_hat_t_stat$predictions)
  min_tau_hat_df <- tau_hat_t_stat %>% 
    filter(predictions == min_tau_hat)
  return(min_tau_hat_df)
}

find_number_of_defiers <- function(tau_hat_t_stat, tau){
  n_defiers_true <- sum(tau < 0)
  n_defiers_estimated <- sum(tau_hat_t_stat$predictions < 0)
  n_significant_defiers <- sum(tau_hat_t_stat$reject_H0)
  df <- tibble(n_defiers_true, n_defiers_estimated, n_significant_defiers)
  return(df)
}

```


# Simulations


## Defier Beta

Estimating tau with defiers and exploring how our ability to detect defiers changes as the defier slope coefficient increases in absolute value - we don't hold ATE constant here so ATE tends to 0 as we explore the more extreme defier values. Commented code indicates the underlying commands necessary to run one draw of the model.
```{r}

# binary_instrument <- rbinom(1000, 1, 0.5)
# binary_tau <- create_binary_complier_defier(1000, beta_complier =  0.4, beta_defier = -0.1, prop_defier = 0.25)
# 
# sim_df <- create_simulated_data(instrument = binary_instrument, tau = binary_tau)
# 
# tau_hat <- estimate_heterogeneous_tau(sim_df$X, sim_df$Y, sim_df$instrument)
# tau_hat_augmented <- perform_inference_mono(tau_hat, alpha = 0.05, n_covariates = 5)
# violates_monotonicity_check(tau_hat_augmented)


run_defier_beta_simulations <- function(beta_defier, N, num.threads = NULL, verbose = FALSE){
  binary_instrument <- rbinom(N, 1, 0.5)
  binary_tau <- create_binary_complier_defier(N,
                                              beta_complier = 0.5,
                                              beta_defier = beta_defier,
                                              prop_defier = 0.25)
  sim_df <- create_simulated_data(instrument = binary_instrument, tau = binary_tau, n = N)
  tau_hat <- estimate_heterogeneous_tau(sim_df$X, sim_df$Y, sim_df$instrument, num.threads = num.threads)
  tau_hat_augmented <- perform_inference_mono(tau_hat, alpha = 0.05, n_covariates = 5)

  if (verbose == TRUE){
    mono_violated <- violates_monotonicity_check(tau_hat_augmented)
    print(paste0(beta_defier, "Monotonicity Violated: ", mono_violated))
    return(mono_violated)
  }
  
  n_defier_summary <- find_number_of_defiers(tau_hat_augmented, binary_tau)
  return(n_defier_summary)
}
```



Here we read in a csv containing simulated draws to save time.
```{r}
# library(purrr)
# tictoc::tic()
defier_beta_binary_taus <- read.csv("beta_binary_taus.csv") %>% as_tibble()
# defier_beta_binary_taus <- rep(seq(from = 0, to = -1.5, by = -0.1), 10) %>%
#   map_df(., ~(run_defier_beta_simulations(N = 1000, verbose = FALSE, beta_defier = .) %>% 
#            mutate(beta_defier = .x)))
# tictoc::toc()
# beepr::beep()

```



```{r}
defier_beta_binary_taus %>% 
  ggplot(aes(x = beta_defier, y = n_significant_defiers, colour = n_significant_defiers)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(title = "Defier detection improves as negative treatment effects increase in size") +
  scale_color_continuous(low = "grey", high = "red") +
  guides(colour = "none")
```



## Defier Size

Now we do the same but vary the proportion of defiers present in the data - again ATE tends to 0 in the tail.
```{r}
run_defier_proportion_simulation <- function(prop_defier, N, num.threads = NULL, verbose = FALSE){
  binary_instrument <- rbinom(N, 1, 0.5)
  binary_tau <- create_binary_complier_defier(N,
                                              beta_complier = 0.5,
                                              beta_defier = -0.5,
                                              prop_defier = prop_defier)
  sim_df <- create_simulated_data(instrument = binary_instrument, tau = binary_tau, n = N)
  tau_hat <- estimate_heterogeneous_tau(sim_df$X, sim_df$Y, sim_df$instrument, num.threads = num.threads)
  tau_hat_augmented <- perform_inference_mono(tau_hat, alpha = 0.05, n_covariates = 5)

  if (verbose == TRUE){
    mono_violated <- violates_monotonicity_check(tau_hat_augmented)
    print(paste0(beta_defier, "Monotonicity Violated: ", mono_violated))
    return(mono_violated)
  }
  
  n_defier_summary <- find_number_of_defiers(tau_hat_augmented, binary_tau)
  return(n_defier_summary)
}
```



Again, loading cached data.
```{r}
# tictoc::tic()
defier_prop_binary_taus <- read.csv("defier_prop_binary_taus.csv")
# defier_prop_binary_taus <- rep(seq(from = 0, to = 0.5, by = 0.01), 10) %>%
#   map_df(., ~(run_defier_proportion_simulation(N = 1000, verbose = FALSE, prop_defier = .) %>% 
#            mutate(defier_proportion = .x)))
# tictoc::toc()
# beepr::beep()
```


```{r}
defier_prop_binary_taus %>% 
  ggplot(aes(x = defier_proportion, y = n_significant_defiers, colour = n_significant_defiers)) +
  geom_point() +
  theme_minimal() +
  labs(title = "As proportion of defiers increase we detect more defiers") +
  guides(colour = "none") +
  scale_color_continuous(low = "grey", high = "red")
```


```{r}
library(RColorBrewer)
defier_prop_binary_taus %>% 
  mutate(any_defiers = ifelse(n_significant_defiers > 0, 1, 0)) %>% 
  group_by(defier_proportion) %>% 
  summarise(defiers_found = sum(any_defiers)) %>% 
  ggplot(aes(x = defier_proportion, y = defiers_found, colour = defiers_found)) +
  geom_point(size = 2) +
  guides(colour = "none") +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 1), minor_breaks = NULL) +
  scale_color_continuous(low = "grey", high = "red")  +
  theme_minimal() +
  labs(title = "As proportion of defiers increase our ability to detect at least one defier increases",
       x = "Proportion of defiers present in the data",
       y = "Occasions defiers found",
       caption = "After ten simulations per defier proportion, a value of nine indicates we found \n statistically significant defiers nine times out of ten.")
  
```


We need to repeat the above but holding ATE constant.

# p-values

Now we explore the p-values resulting from heterogeneous $\pi_i$ estimation. We borrow a common tactic in studies of genome data and compare the QQ p-value plots on the negative log(10) scale. UNDER THE NULL HYPOTHESIS P VALUES SHOULD BE UNIFORMLY DISTRIBUTED ON THE INTERVAL [0,1].

However, there's a huge problem. We define:
$$
H_0: \pi_i = 0 \\
H_1: \pi_i < 0
$$

But of course $\pi_i$ is often positive - it's average certainly is since we estimate a positive first stage (by design monotonicity has that whole "vice versa" thing going on). Therefore, when we have significant POSITIVE $\hat{\pi_i}$ the p values will be particularly large and this thing won't be uniformly distributed which implies we reject $H_0$ BUT AS EVERYONE KNOWS THIS DOESN'T IMPLY WE ACCEPT $H_1$ THIS IS A PROBLEM AS NON-UNIFORMITY OF THE P VALUES CAN EITHER BE BECAUSE PI IS POSITIVE OR NEGATIVE AND DISENTANGLING THE TWO RIGOROUSLY ISN'T GOING TOO HOT.


The negative log ten scale just means that really, really small p values (the ones we're essentially interested in) appear in the top right hand corner of the plot and just makes stuff easier to distinguish in the tail.
```{r}
library(scales)
tau_simulation <- function(N = 1000, beta_complier, beta_defier, prop_defier){
  binary_instrument <- rbinom(N, 1, 0.5)
  binary_tau <- create_binary_complier_defier(N,
                                              beta_complier = beta_complier,
                                              beta_defier = beta_defier,
                                              prop_defier = prop_defier)
  sim_df <- create_simulated_data(instrument = binary_instrument, tau = binary_tau, n = N)
  tau_hat <- estimate_heterogeneous_tau(sim_df$X, sim_df$Y, sim_df$instrument)
  tau_hat_augmented <- perform_inference_mono(tau_hat, alpha = 0.05, n_covariates = 5) %>% 
    as_tibble()
  return(tau_hat_augmented)
}


negative_log_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("negative_log-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

tau_sim_defiers <- tau_simulation(beta_complier = 0.5, beta_defier = -0.2, prop_defier = 0.25)

tau_sim_defiers_p <- tau_sim_defiers %>% 
  mutate(p_value = pnorm(t_stat))
tau_sim_defiers_p %>% 
  ggplot(aes(sample = p_value)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values DEFIERS",
       subtitle = "Log(10) Scale")


tau_sim_defiers_p %>% 
  ggplot(aes(sample = p_value)) +
  stat_qq(distribution = qunif, aes(colour = reject_H0))  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  labs(title = "QQ plot of P-values",
       subtitle = "Normal Scale")
```

The straight lines throughout represent where the data should like under the null.


```{r}
tau_sim_compliers <- tau_simulation(beta_complier = 0.5, beta_defier = 0.5, prop_defier = 0.5)

tau_sim_compliers_p <- tau_sim_compliers %>% 
  mutate(p_value = pnorm(t_stat))
tau_sim_compliers_p %>% 
  ggplot(aes(sample = p_value)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values COMPLIERS",
       subtitle = "Log(10) Scale")


tau_sim_compliers_p %>% 
  ggplot(aes(sample = p_value)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  labs(title = "QQ plot of P-values COMPLIERS",
       subtitle = "Normal Scale")
```

```{r}
tau_sim_defiers_p <- tau_sim_defiers_p %>% 
  mutate(type = "defiers")
tau_sim_compliers_p <- tau_sim_compliers_p %>% 
  mutate(type = "compliers")

tau_comparison_p <-bind_rows(tau_sim_compliers_p,
                             tau_sim_defiers_p)

tau_comparison_p %>% 
  ggplot(aes(sample = p_value)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values") +
  facet_wrap(~type)
```



```{r}
library(broom)
library(purrr)
run_one_model <- function(dummy_arg, sign_factor, N = 1000){
  if (sign_factor == 1){
    indicator <- 1
  } else {
    indicator <- rbinom(1, 1, 0.8)  
  }
  
  X <- matrix(rnorm(N*5), N, 5)
  y <- rnorm(N, sd = 10) + X[, 1]*5*indicator + X[, 1]*-5*(1-indicator)
  model <- lm(y ~ X) %>% 
    tidy() %>%
    mutate(one_sided_p = pnorm(statistic))
  
  return(model)
}
p_vals <- 1:1000 %>% 
  map_df(run_one_model, N = 1000, sign_factor = 1)
p_vals %>% 
  ggplot(aes(sample = one_sided_p)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  theme_minimal() +
  labs(title = "QQ plot of P-values NO DEFIERS") +
    scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10))  +
  facet_wrap(~term)
p_vals_negative <- 1:1000 %>% 
  map_df(run_one_model, N = 1000, sign_factor = -1)
p_vals_negative %>% 
  ggplot(aes(sample = one_sided_p)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  theme_minimal() +
  labs(title = "QQ plot of P-values DEFIERS PRESENT") +
    scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  facet_wrap(~term)
```

# Now holding ATE constant

TODO: write a function that balances ATE as we change stuff - currently ATE CHANGES.
```{r}
## Find Betas to balance ATE given range of beta to explore for defiers

## This but with proportion defiers

## Check if ATE balances function goes here.

## Run simulation function goes here.
```





# Investigating False Discovery Rate

Confirming that setting $\alpha = 0.05$ will give 5\% false positives:
```{r}
library(furrr)
plan(multiprocess)
library(broom)
run_many_lm <- function(dummy_arg, coef_x){
  x <- rnorm(1000)
  y <- coef_x*x + rnorm(1000)
  model <- lm(y ~ x)
  model <- model %>% 
    tidy()
  return(model)
}

many_p_vals <- 1:10000 %>% 
  future_map_dfr(run_many_lm, coef_x = 0, .options = future_options(packages = "broom")) %>% 
  mutate(signif_at_5 = ifelse(p.value < 0.05, 1, 0))

many_p_vals %>%
  filter(term == "x") %>% 
  summarise(mean(signif_at_5))

many_p_vals %>% 
  ggplot(aes(x = p.value, y = term, fill = term)) +
  ggridges::geom_density_ridges() +
  ggridges::theme_ridges() +
  labs(title = "Clearly Uniform As Expected")
  
```

Now one sided:
```{r}
many_p_vals %>% 
  mutate(one_side_p = pt(statistic, df = 998),
         reject_p_oneside = ifelse(one_side_p < 0.05, 1, 0)) %>% 
  summarise(mean_one = mean(reject_p_oneside),
            mean_two = mean(signif_at_5))
```

How about for random forest - we only use 10 simulation draws as this takes FOREVER:
```{r}
anonymous_tau_simulation <- function(dummy_arg, N = 1000, beta_complier, beta_defier, prop_defier){
  tau_simulation(N = N, beta_complier = beta_complier, beta_defier = beta_defier, prop_defier = prop_defier) %>% 
    mutate(draw = dummy_arg)
}

many_tau_pvals <- 1:10 %>% 
  map_df(anonymous_tau_simulation, N = 1000, beta_complier = 0, beta_defier = 0, prop_defier = 0.5)

many_tau_pvals <- many_tau_pvals %>% 
  mutate(two_pval = 2*pt(-abs(t_stat), df = 994 ),
         reject_H0_twosided = ifelse(two_pval < 0.05, 1, 0),
         one_pval = pt(t_stat, df = 994),
         reject_H0_onesided = ifelse(one_pval < 0.05, 1, 0))

many_tau_pvals %>% 
  ggplot(aes(x = two_pval)) +
  geom_histogram() +
  facet_wrap(~draw) +
  labs(title = "Histogram of two sided p value per simulation draw")


many_tau_pvals %>% 
  ggplot(aes(x = one_pval)) +
  geom_histogram() +
  facet_wrap(~draw) +
  labs(title = "Histogram of one sided p value per simulation draw")
```


This is how often we commit a type 1 error per regression draw- i.e. we find how many times we reject the null for each $\pi_i$ AFTER ONE REGRESSION. I have no prior on what this should be - it looks like there's a lot of variance though. Increasing number of datapoints should let us estimate this better.
```{r}
many_tau_pvals %>% 
  group_by(draw) %>% 
  summarise(reject_H0_pct_two = mean(reject_H0_twosided),
            reject_H0_pct_one = mean(reject_H0_onesided))
```

This is the total number of times we reject the null across all the regressions.
```{r}
many_tau_pvals %>% 
  summarise(reject_H0_pct_two = mean(reject_H0_twosided),
            reject_H0_pct_one = mean(reject_H0_onesided))
```


We want to know how many times we reject the null at least once in a regression. Increasing number of simulations should let us estimate this better.
```{r}
many_tau_pvals %>% 
  group_by(draw) %>% 
  summarise(rejected_at_least_once_twosided = ifelse(sum(reject_H0_twosided), 1, 0),
            rejected_at_least_once_onesided = ifelse(sum(reject_H0_onesided), 1, 0))
```

Clearly we need to make a correction:
```{r}
many_tau_pvals %>% 
  group_by(draw) %>% 
  summarise(rejected_at_least_once_twosided = ifelse(sum(reject_H0_twosided), 1, 0),
            rejected_at_least_once_onesided = ifelse(sum(reject_H0_onesided), 1, 0))%>% 
  ungroup() %>% 
  summarise(rejected_H0_once_pct_twosided = mean(rejected_at_least_once_twosided),
            rejected_H0_once_pct_onesided = mean(rejected_at_least_once_onesided))
```

Currently our false discovery rate is 100\% - not good.
