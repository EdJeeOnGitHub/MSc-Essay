---
title: "Detecting Defiers: An Empirical Investigation"
author: "Ed Jee"
date: "22 January 2019"
abstract: "I present some practical tests for detecting failure of the monotonicity assumption essential for causal identification under the LATE theorem. Simulations show mixed results for the Bayesian and Random Forest methods whilst the traditional practice of checking heterogeneous first stage treatment effects performs best. I apply these tests to a sample of papers in labour economics using instrumental variables estimation with an emphasis on visualisation and exploration rather than rigid adherence to Fisher hypothesis testing methods although these are supplied as well."
output:
    html_document:
      code_folding: hide
      highlight: tango
      theme: journal
      toc: yes
      toc_float: yes
bibliography: bibliography.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```




&nbsp;
&nbsp;

The LATE theorem is a cornerstone of identification in economics and labour economists in particular have popularised and preached its virtues. Considering the theorem's importance relatively little effort has been expended ensuring the theorem's assumptions are met in the dataset in question. This essay aims to promote a practical methodology that can be incorporated into current instrumental variables workflow in order to clearly aid researchers in verifying that necessary, but not sufficient, conditions are met empirically in the sample.

Checking that the first stage "goes the right way" through the use of interaction terms or subsampling is common knowledge amongst applied practitioners but rarely discussed in depth. I formalise this notion and present some novel contributions of potential interest to social science researchers using saturated first stage regressions, multiple comparison adjustments and negative log-log $p$-value transforms popularised by genome wide association studies (GWAS) to present visually striking evidence for or against monotonicity. Next, I show how advances in causal econometric inference using machine learning techniques, developed by @Wager_and_Athey, can be adapted to estimate the underlying first-stage heterogeneity and provide an alternative to the saturated regression model. I explore the power of the two tests in simulation studies in comparison to @RESTAT's monotonicity test and find XYZ. Finally, I take the tests to the data by applying the methodologies to various seminal papers in labour economics and fail to find significant evidence of defiers.

# The LATE Theorem


The LATE theorem [@Angrist_Imbens] describes four key assumptions under which instrumental variables regression will identify a causal effect for a specific subpopulation, "compliers", in the presence of heterogeneous effects.

Using the random coefficient notation of Mostly Harmless Econometrics [@MHE] we have a  potential outcome $Y_i(d, z)$ corresponding to an individual $i$ with treatment status $D_i = d$ and instrument value $Z_i = z$. Observed treatment status is:

$$
D_i = D_{0i} + (D_{1i} - D_{0i})Z_i = \pi_0 + \pi_{1i}Z_i + \epsilon_i
$$

where $\pi_{1i} = (D_{1i} - D_{0i})$ is the heterogeneous causal effect of $Z_i$ on $D_i$ 
The LATE assumptions are:

1. Independence. $\{Y_i(D_{1i}, 1), Y_i(D_{0i}, 0), D_{1i}, D_{0i}\}\  \amalg  \ Z_i$.
2. Exclusion. $Y_i(d, 0) = Y_i(d, 1) = Y_{di}  \ \text{for} \ d = 0,1$.
3. First-Stage. $E[D_{1i} - D_{0i}] \neq 0$.
4. Monotonicity. $D_{1i} - D_{0i} \geq 0 \ \forall \ i \ \text{or vice versa.}$^[For simplicity the rest of the essay assumes $D_{1i} - D_{0i} \geq 0$ unless explicitly stated otherwise.]


Under assumptions 1-4:

$$
\frac{E[Y_i | Z_i = 1] - E[Y_i | Z_i = 0]}{E[D_i | Z_i = 1] - E[D_i | z_i = 0]} = E[Y_{1i} - Y_{0i} | D_{1i} > D_{01}] = E[\rho_i | \pi_{1i} > 0]
$$

The Wald estimator is the Local Average Treatment Effect (LATE) - that is, the average treatment effect for the compliers. The monotonicity assumption is key because it rules out "defiers"; those who would have taken the treatment if they hadn't been assigned the instrument but upon instrument assignment are induced not to take the treatment. In the presence of defiers the equation above no longer estimates LATE but some weighted average of the effect for compliers and defiers.

The Wald estimator under assumptions 1-4 is often criticised for lack of external validity - it's hard to argue that the effect for compliers can be generalised to the rest of the population unless the treatment effect is the same for everyone (unlikely) or assignment to complier, defier, always-taker etc. is as good as random (i.e. $corr(\rho_i, \pi_{1i}) = 0$). However, an advantage of LATE is that the estimate is often exactly what we want to know from a policy perspective - a programme's effect on those likely to respond to the programme is more interesting to us than the effect on the entire population if univeral compliance is unlikely. 

On the other hand the Wald estimator in the presence of defiers is near useless to us. Not only does it lack external validity but it fails to uncover a meaningful internally valid estimate. This, in part, motivates the importance of checking monotonicity.


## Literature

There are two papers of direct relevance to monotonicity tests. @kitagawa's test for instrument validity and @RESTAT's.   





# The Tests

## First Stage Interactions

Common practice in applied work involves checking that the regression first stage "goes the same way" for all subgroups present in a dataset. In the simple binary covariate case this involves checking that $\hat{\pi}_{1im} > 0$ for $m = 0,1$ where $m$ indicates which sub-population the sample is drawn from, male or female say. This is equivalent to running the saturated regression model:
$$
D_i = \pi_0 + \pi_{1i}Z_i + \pi_{2i}m_i + \pi_{3i}(Z_i \times m_i) + \epsilon_i
$$

and testing $\hat{\pi}_{1i} > 0$ and $\hat{\pi}_{1i} + \hat{\pi}_{3i} > 0$. Extending this framework to multiple, continous and binary-valued covariates is relatively straightforward:

$$
D_i = \pi_0 + \pi_{1i}Z_i + \sum_{k=1}^K (\gamma_{ki}x_{ki} +  \delta_{ki}(Z_i \times x_{ki})) + \epsilon_i
$$

where $x_{ki}$ is a vector of $K$ observed covariates. Differentiation^[Or equivalently, taking differences in the binary case.] with respect to the instrument $Z_i$ gives:

$$
\frac{\partial D_i}{\partial Z_i} = \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki}
$$

and therefore we wish to test hypotheses of the form:

$$
\begin{aligned}
  H_{0i}: \frac{\partial D_i}{\partial Z_i} = \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki} &= 0 \\
  H_{1i}: \frac{\partial D_i}{\partial Z_i} = \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki} &< 0
\end{aligned}
$$
In the binary covariate case we could simply estimate the saturated model and test each partial derivative separately - one for $m = 1$ and another for $m = 0$. Moving to the continuous case is essentially the same however now we have as many partial derivatives we wish to test as datapoints - our hypotheses are indexed by $i$ because unlike the discrete covariate case, every individual takes a unique $X_i$ value. Furthermore, LATE theorem assumption 4 require monotonicity for all $i$ - the partial derivative, $\frac{\partial D_i}{\partial Z_i}$ must be positive for all $i$.

Therefore, our monotonicity test neatly corresponds with the set, or complete, null [@shaffer]:

$$
\begin{aligned}
  H_0^C: \cap_{i \in N} \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki} &= 0 \\
  H_1^C: \cap_{i \in N} \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki} &< 0
\end{aligned}
$$


Any test of this nature immediately faces two problems. First, we must consider whether control of the family wise error rate (FWER) in the face of $N$ simultaneous statistical inferences is necessary. Second, we must be confident of test power when performing $N$ inferences based off $N$ datapoints.

Fortunately, our tests are logically related - if we fail to reject the most statistically significant defier this implies we must fail to reject the next significant defier and so on. Likewise, if we do reject the null hypothesis and conclude there's evidence of a defier, considering the most adverse test statistic to the null, then our job is done - we only require evidence of _one_ defier to conclude monotonicity has failed. 

The above can be reformulated through consideration of hypothesis hierarchy and __closure principle__ of testing. The highest hypothesis in the closed hierarchy of hypotheses considered is the complete intersection null $H_0^C: \cap_{i \in N} \pi_{1i} + \sum_{k=1}^K \delta_{ki}x_{ki} = 0$ however, immediately below this is the set of minimal hypotheses and it's sufficient to reject just one of these minimal hypotheses to reject, essentially, our set null and question of interest. In other words, we can merely focus on the smallest $p$-value in a given dataset.

Searching for the most adverse test-static, almost conditioning on significance, seems like a guaranteed way to introduce "fishing" or "$p$-hacking" - to ease such concerns I present a rigorous array of power and size simulations and show that a Romano-Wolf adjustment, which lets the data speak to hypothesis dependency through resampling, is far too conservative for the problem at hand.


Moving onto our second concern, test power; the model parameters are well-identified since whilst we're testing $N$ hypotheses, the number of effective parameters we wish to estimate are much lower in fact, only $2K + 1$. The problem can be reconceptualised as constructing prediction intervals for the partial derivates which, whilst heterogeneous, only vary at the subgroup level. This reduction in granularity speaks to the trade-off inherent in heterogeneous causal identification. Whilst we may believe treatment effects vary at the individual level, using conventional methods in the cross-section, we can only identify an average treatment effect for observed subgroups - later in the essay I attempt to use @Wager_and_Athey's causal random forest to address this limitation. 

In conclusion, the first stage interaction test involves estimating the saturated regression and forming multiplicity adjusted one-sided test statistics for the partial derivative $\frac{ \hat{\partial D_i}}{ \hat{\partial Z_i}}$ and finding the most adverse test statistic/minimum $p$-value.

```{r first_stage_test_function}
library(Rfast)
library(margins)
library(dplyr)
library(ggplot2)
library(ggExtra)
library(grf)
library(tibble)

find_SEs <- function(model_data_no_y, model_vcov, instrument){
  model_data_no_y <- model_data_no_y %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0("~", "instrument", "*."))
  
  model_matrix <- model_data_no_y %>% 
    mutate(instrument = 1) %>% 
    model.matrix(model_formula, data = .)
  
  gradient_matrix_kinda <- model_matrix %>%
    as_tibble() %>% 
    mutate_at(vars(-contains(":")), ~(. = 0)) %>% 
    mutate(instrument = 1) %>% 
    as.matrix()
  
  split_indices <- seq(from = 1, to = nrow(gradient_matrix_kinda), by = 10000) %>% 
    c(nrow(gradient_matrix_kinda))
  
  if (length(split_indices) < 3){
    vcov_dydx_intermediate <- Rfast::mat.mult(gradient_matrix_kinda, model_vcov)
    vcov_dydx <- Rfast::mat.mult(vcov_dydx_intermediate,
                                 Rfast::transpose(gradient_matrix_kinda))
    SE_dydx <- sqrt(diag(vcov_dydx))
    
  } else {
    baby_SE <- matrix(nrow = nrow(gradient_matrix_kinda), ncol = 1)
    for (i in 1:(length(split_indices)-1)){
      baby_matrix <- gradient_matrix_kinda[split_indices[[i]]:split_indices[[i+1]], ]
      # print(paste0(split_indices[i],"to", split_indices[i+1]))
      baby_vcov <- Rfast::mat.mult(baby_matrix, model_vcov)
      baby_vcov <- Rfast::mat.mult(baby_vcov, Rfast::transpose(baby_matrix))
      baby_SE[split_indices[[i]]:split_indices[[i+1]], ] <- sqrt(diag(baby_vcov))
      i <- i + 1
    }
    SE_dydx <- baby_SE[, 1]
  }
  
  return(SE_dydx)
  
} 
run_first_stage_interactions_fast <- function(dataset, dependent_variable, instrument, weights = NULL){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula, weights = weights)
  degrees_freedom <- first_stage_fit$df.residual
  instrument_dummy_val <- dataset$instrument[1]
  
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    mutate(instrument = instrument_dummy_val)
  first_stage_margins <- dydx(model = first_stage_fit, data = dataset_unique, variable = "instrument") 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins$instrument <- dataset$instrument
  df_margins$SE_dydx_instrument <- find_SEs(dataset_unique, vcov(first_stage_fit), instrument)
  
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom),
           pval_holm = p.adjust(pval_one_neg, method = "holm"))
  df_margins$dependent_variable <- dataset %>% 
    select(dependent_variable) %>% 
    pull()
  return(df_margins)
}

```




## Random Forest

[Regression Tree](https://commons.wikimedia.org/wiki/File:Cart_tree_kyphosis.png#/media/File:Cart_tree_kyphosis.png)

Random forest is this but with bagging, bootstrapped aggregation, and some other stuff to prevent overfitting.


Causal Random Forest is the above but with slightly different decision rules to ensure causal estimates.

## Simulations


### Power Simulations

Test power is the ability of a test to correctly reject a null hypothesis. Classical frequentist testing in econometrics usually sets a desired test size (control of the type 1 error rate) and uses the most powerful test possible with little thought to test size-power trade-off. In order to measure test power I generate 2000 draws of a simulated dataset, with 1,000, 5,000 and 10,000 observations respectively, using the following data generating process:

$$
D_i = \pi_0 + \pi_{1i}Z_i + \sum_{k=1}^4 (\gamma_{ki}x_{ki} +  \delta_{ki}(Z_i \times x_{ki})) + \epsilon_i; \ \epsilon_i \sim N(0, 5^2)
$$
  Covariates are drawn from a multivariate normal mean 0 and variance $\Sigma$.^[I use Cholesky decomposition to generate p.s.d $\Sigma = LL'$ by simulating entries of $L$ drawn from $U(-1, 1)$] The fourth covariate is transformed into a dummy variable depending on its sign and Z is a binary instrument drawn from a Bernoulli distribution with probability one half.

For each draw of the data I run the saturated first stage model and causal random forest and record: the number of "true" defiers in the dataset; the number of estimated defiers; and the defier test statistic/$p$-value.

```{r sim_data_generation_and_power_test}

create_fake_data <- function(N, model_betas, force_positive = FALSE){
  mu <- rep(0, 4)
  
  A <- matrix(runif(4^2)*2-1, ncol=4) 
  Sigma <- t(A) %*% A
  
  if (force_positive == TRUE){
    X_data <- abs(MASS::mvrnorm(n = N, mu = mu, Sigma = Sigma)) %>% 
      as_tibble() %>% 
      mutate(Z = rbinom(n = N, 1, 0.5),
             V4 = ifelse(V4 > 0.5, 1, 0))
  } else {
    X_data <- MASS::mvrnorm(n = N, mu = mu, Sigma = Sigma) %>% 
      as_tibble() %>% 
      mutate(Z = rbinom(n = N, 1, 0.5),
             V4 = ifelse(V4 > 0, 1, 0))
  }
  
  X_data_interactions <- model.matrix(~ Z*., data = X_data)
  D <- X_data_interactions %*% model_betas
  sim_data <- X_data_interactions %>% 
    as_tibble() %>% 
    mutate(D = D[, 1] + rnorm(N)*5)
  return(sim_data)
}

power_test <- function(coefs, sim_data){
  names(coefs) <- names(sim_data)[1:10]
  
  
  first_stage_model <- sim_data %>% 
    select_at(vars(-contains(":"), -`(Intercept)`)) %>% 
    run_first_stage_interactions_fast(.,
                                      "D",
                                      "Z") %>% 
    mutate(row_id = row_number(),
           pval_one_pos = pnorm(-t_stat),
           model = "saturated first stage")
  
  interaction_coefs <- c(coefs[2],
                         coefs[7:10])
  interaction_X <- sim_data %>% 
    select_at(vars(Z, contains("V"), -contains(":"))) %>% 
    mutate(Z = 1)
  interaction_X <- model.matrix(~Z*., data = interaction_X) %>% 
    as_tibble() %>% 
    select_at(vars(Z, contains(":"))) %>% 
    as.matrix()
  
  true_dydx <- interaction_X %*% interaction_coefs
  first_stage_model$true_dydx <- true_dydx[,1]
  forest_model <- sim_first_stage_forest(sim_data)
  
  forest_full_wide <- left_join(forest_model,
                                first_stage_model %>% 
                                  select_at(vars(row_id,
                                                 contains("V", ignore.case = FALSE),
                                                 instrument,
                                                 true_dydx,
                                                 dependent_variable)),
                                by = "row_id") %>% 
    rename("dydx_instrument" = predictions,
           "SE_dydx_instrument" = sigma_hat,
           "dydx_lo" = prediction_lo,
           "dydx_hi" = prediction_hi) %>% 
    select(-variance.estimates,
           -debiased.error) %>% 
    mutate(model = "forest")
  
  models_df_long <- suppressWarnings(bind_rows(first_stage_model %>% 
                                                 select(-pval_holm),
                                               forest_full_wide))
  
  return(models_df_long)
}


simulation_func <- function(x, force_positive = FALSE){
  sim_data <- create_fake_data(N = 1000,
                               model_betas = x,
                               force_positive = force_positive)
  
  pw_test_data <- power_test(x, sim_data)
  
  estimated_coef <- lm(dependent_variable ~ instrument + V1 + V2 + V3 + V4, data = pw_test_data) %>% 
    tidy() %>% 
    filter(term == "instrument") %>% 
    select(estimate)
  
  pw_test_data$estimate <- estimated_coef[[1]]
  
  power_sim_df <- pw_test_data %>%   
    mutate(defier_true = !(sign(true_dydx) == (sign(estimate))),
           defier_estimated = !(sign(dydx_instrument) == (sign(estimate)))) %>% 
    group_by(model) %>% 
    summarise(min_tstat = min(t_stat),
              max_tstat = max(t_stat),
              pval_one_neg = min(pval_one_neg),
              mean_dydx = mean(dydx_instrument),
              pval_one_pos = min(pval_one_pos),
              n_defiers_true = sum(defier_true),
              pct_defiers_true = n_defiers_true/nrow(pw_test_data),
              n_defiers_estimated = sum(defier_estimated),
              pct_defiers_estimated = n_defiers_estimated/nrow(pw_test_data),
              estimate = first(estimate)) %>% 
    mutate(pval_defier = ifelse(estimate > 0,
                                pval_one_neg,
                                pval_one_pos))
  return(power_sim_df)
}

```



Model parameters are drawn from a uniform distribution with support from -1 to 1. Rather than explicitly generating a positive main effect and defiers at given proportions I let the random draws determine the simulated data properties and discretise the data into 1\% defier bins - this gives good coverage of the defier space up to concentrations of 40\%. However, past 40\% the simulations become particularly uninformative - there's very few simulation draws in this region, typically 1\% of all draws due to the nature of the DGP used. Furthermore, the distinction between defier and complier becomes murky when approaching an even split in the population - if this situation arises in practice it's questionable whether LATE really is the estimator of interest to a researcher.

```{r power_simulation}
coef_matrix <- matrix(runif(100*10, -1, 1), 100, 10)
coef_matrix_df <- coef_matrix %>% 
  as_tibble()
factor_pos <- ifelse(rowMeans(coef_matrix) < 0, -1, 1) 

coef_list <- lapply(seq_len(nrow(coef_matrix)), function(i) coef_matrix[i,]*factor_pos[i])


run_sim <- FALSE

if (run_sim) {
  library(furrr)
  plan(multisession)
  
  simulations_power <- coef_list %>% 
    future_map_dfr(simulation_func,
                   .options = future_options(globals = c("sim_data",
                                                         "run_first_stage_interactions_fast",
                                                         "find_SEs",
                                                         "create_fake_data",
                                                         "simulation_func",
                                                         "power_test",
                                                         "sim_first_stage_forest"),
                                             packages = c("dplyr",
                                                          "modelr",
                                                          "margins",
                                                          "broom",
                                                          "grf")),
                   .progress = TRUE)
  
  
  
  plan(sequential)
  # write.csv(simulations_power, file = "power_simulations.csv", row.names = FALSE)
  # write.csv(simulations_power, file = "power_simulations_both.csv", row.names = FALSE)  
} else {
  simulations_power_large <- readr::read_csv("C:/Users/edjee/Dropbox/Ed/power_simulations_both_large.csv") %>% 
    mutate(N = "Large")
  simulations_power_medium <- readr::read_csv("C:/Users/edjee/Dropbox/Ed/power_simulations_both_medium.csv") %>% 
    mutate(N = "Medium")
  simulations_power_small <- readr::read_csv("C:/Users/edjee/Dropbox/Ed/power_simulations_both_small.csv") %>% 
    mutate(N = "Small")
  simulations_power <- bind_rows(simulations_power_small,
                                 simulations_power_medium,
                                 simulations_power_large) %>% 
    mutate(N = factor(N, levels = c("Small", "Medium", "Large")))
}

simulations_power <- simulations_power %>% 
  mutate(model = tools::toTitleCase(model))

```


Throughout the essay I use an inverted y-axis when displaying $p$-values - the reason for this is two-fold. First, when considering thousands of $p$-values, as we are in this essay, it's common to use a negative log transform, popularised by biostatistics and genome studies. Displaying the "most significant" $p$-values at the very top of the visualisation makes better use of the space in a figure - we care less about the null hypothesis $p$-values we're least able to reject. Secondly, inverting the y-axis maintains consistency when we move to the negative log transform rather than switching between visualisation paradigms.

It's clear from the figure below that at even moderate defier levels both tests are extremely powerful. When considering the saturated first stage test this is hardly surprising - it has long been acknowledged that testing whether a first stage "goes the right way" using sub-samples or interaction terms is a valid test of monotonicity and we'd expect test properties to be similar to standard frequentist testing of OLS.

The random forest method, too, performs surprisingly well - even better than the saturated first stage test it would seem at first glance. Both tests improve substantially as sample size increases and as defier proportion increases as we'd expect.

```{r p_value_normal_scale_plot, fig.height=10, fig.width=10}
library(scales)
negative_log_trans <- function(base = exp(1)) {
  trans <- function(x) -log(x, base)
  inv <- function(x) base^(-x)
  trans_new(paste0("negative_log-", format(base)), trans, inv, 
            log_breaks(base = base), 
            domain = c(1e-100, Inf))
}


simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15) +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  guides(colour = "none") +
  scale_y_reverse() +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  facet_grid(N~model) +
  labs(x = "Defier Percentage",
       y = "P-Value",
       caption = "Note: Y-axis scale inverted. \n Dashed line indicates a p-value of 0.05.",
       title = "P-Values from Power Simulations") +
  theme_minimal()
```


The difference between the figure using a linear scale and $p$-values displayed on a log scale, below, clearly motivates the use of a log transform. $p$-values from the medium and larger dataset are orders of magnitude smaller than the $p$-values from the smallest dataset as we'd expect.



```{r p_val_power_neg_log_10, fig.height=10, fig.width=10}

simulations_power %>% 
  unite(mod_N, model, N, remove = FALSE) %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             group = mod_N)) +
  geom_point(alpha = 0.15, aes(colour = model)) +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(colour = "none") +
  theme_minimal() +
  facet_grid(N~model, scales = "free_y") +
  labs(x = "Defier Percentage",
       y = "P-Value",
       caption = "Note: Y-Axis on negative log(10) scale. \n Dashed line indicates a p-value of 0.05. \n Line of best fit in purple.",
       title = "P-Values from Power Simulations") +
  geom_smooth(method = lm,
              se = FALSE,
              alpha = 0.2,
              colour = "violetred")

```



As defier proportion increases test power increases rapidly. For the larger and medium dataset the ability to detect defiers at even levels as small as 2\% is particularly impressive.

```{r p_val_low_defier_plot, fig.height=10, fig.width=10}
simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15,
             aes(colour = model)) +
  geom_hline(yintercept = 0.05, linetype = "longdash") +
  scale_y_reverse() +
  geom_smooth(se = TRUE,
              colour = "violetred",
              alpha = 0.5) +
  scale_x_continuous(limits = c(0, 0.1), labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  facet_grid(N~model, scales = "free_y") +
  guides(colour = "none") +
  labs(x = "Defier Percentage",
       y = "P-Value",
       title = "Power Simulation Results at Low Defier Proportion",
       caption = "Note: Y-axis scale inverted. \n Dashed line indicates a p-value of 0.05.")

```


One concern may be that whilst the tests are capable of detecting defiers, this may be driven by defier activity in the tails. That is, the tests may work but only because of extremely "defiant" defiers since we only consider the most extreme defier in each sample. Fortunately, we can turn to each test's respective model predictions and compare estimated number of defiers against the actual number of defiers present in the data. The results are reassuring, as the number of defiers grow the number of predicted defiers grows too. 

```{r defier_true_vs_estim, fig.height=10, fig.width=10}

simulations_power %>% 
  ggplot(aes(x = n_defiers_true,
             y = n_defiers_estimated,
             colour = model)) +
  geom_point(alpha = 0.15) +
  facet_grid(N~model) +
  geom_abline(slope = 1, intercept = 0) +
  theme_minimal() +
  guides(colour = "none") +
  labs(x = "N True Defiers",
       y = "N Predicted Defiers",
       title = "Defier Predictions vs Reality",
       caption = "Note: Line of equality in black.")
  
```



Write something here? Run regressions on sims?

```{r mean_dydx_plot}
library(RColorBrewer)
p <- simulations_power %>% 
  filter(N == "Large") %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = mean_dydx,
             y = pval_defier,
             colour = factor(sign(estimate)),
             group = sign(estimate))) +
  geom_point(alpha = 0.05) +
  geom_smooth(method = lm, se = FALSE) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  theme_minimal() +
  labs(x = "Mean Instrument Partial Effect",
       y = "P-Value",
       title = "Defier P-Value against Mean Instrument Partial Effect",
       caption = "Note: Y-Axis on negative log(10) scale. Large dataset only.") +
  scale_colour_manual(values = c("#999999", "#E69F00"),
                      name = "Sign of First Stage:",
                      breaks = c("-1", "1"),
                      labels = c("-ve", "+ve")) +
  theme(legend.position = "bottom")

ggMarginal(p,
           type = "histogram",
           groupColour = TRUE,
           groupFill = TRUE) 

```




The simulations show that using medium to large datasets the tests are extremely powerful - even at defier proportions of just 5\% both tests have a near 100\% chance of correctly rejecting the null. The smaller dataset is clearly noisier but again shows promising results - at defier proportions around 20\% the tests are able to pick up the presence of defiers in a sample almost perfectly.


It's hard to make inferences comparing the power of the two tests without creating some measure of underlying uncertainty, such as bootstrapping the simulations again, however with 2000 draws of the data we can be reasonably confident at concluding that the saturated first stage test is more powerful in smaller datasets but is surpassed when moving to the moderate and larger dataset. This result, again, is hardly surprising, we'd hope that methods drawing on advances in machine learning have a comparative advantage as $N$ increases.

Moving from power comparisons to mean $p$-value comparisons makes it easier to estimate the underlying uncertainty by calculating the standard error of the mean in each percentile bin - the reduction in uncertainty is stark when moving from the smaller to larger datasets.
```{r binned_power, fig.height=10, fig.width=10}
sim_bin <- simulations_power %>% 
  mutate(gr=cut(pct_defiers_true, labels = FALSE, breaks= seq(0, 1, by = 0.01))/100) %>% 
  group_by(model,
           N,
           gr) %>%
  mutate(n= n()) %>%
  arrange(gr) %>% 
  mutate(n_rejected = ifelse(pval_defier < 0.05, 1, 0)) %>% 
  mutate(pct_rejected = sum(n_rejected)/n) 

sim_bin_summ <- simulations_power %>% 
  group_by(model,
           N,
           gr=cut(pct_defiers_true,label = FALSE, breaks= seq(0, 1, by = 0.01))) %>% 
  mutate(n= n()) %>%
  arrange(as.numeric(gr)) %>% 
  mutate(n_rejected = ifelse(pval_defier < 0.05, 1, 0)) %>% 
  summarise(pct_rejected = mean(n_rejected),
            sd_rejected = sd(n_rejected),
            n = unique(n),
            mean_true_defier = mean(pct_defiers_true))


sim_bin %>% 
  na.omit() %>% 
  filter(pct_defiers_true < 0.35) %>% 
  ggplot(aes(x = gr, y = pct_rejected, colour = model, group = model)) +
  geom_point() + 
  geom_line() +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(size = "none")  +
  theme(legend.position = "bottom") +
  labs(y = "Proportion Null Rejected",
       x = "Defier Proportion",
       title = "Power As a Function of Defier Proportion") +
  facet_wrap(~N, ncol = 1) +
  scale_x_continuous(breaks = seq(from = 0, 1, 0.05),
                     labels = scales::percent_format(accuracy = 1))


```




```{r pval_mean_plot, fig.height=10, fig.width=10}
sim_bin %>% 
  na.omit() %>% 
  filter(pct_defiers_true < 0.35) %>% 
  summarise(m_pval = mean(pval_defier),
         sd_pval = sd(pval_defier)) %>% 
  ggplot(aes(x = gr, y = m_pval, colour = model, group = model)) +
  geom_point() + 
  geom_line() + 
  geom_linerange(aes(x = gr,
                     ymin = m_pval - 1.96*sd_pval,
                     ymax = m_pval + 1.96*sd_pval)) +
  theme_minimal() +
  guides(size = "none",
         colour = "none") +
  facet_grid(N~model) +
    labs(y = "Mean P-Value",
       x = "Defier Proportion",
       caption = "Note: Dashed line indicates p-value of 0.05. \n 95% Confidence Intervals Displayed.",
       title = "Mean P-Value as a Function of Defier Proportion") +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  scale_y_reverse() +
  scale_x_continuous(breaks = seq(from = 0,
                                  to = 1,
                                  0.1),
                     labels = scales::percent_format(accuracy = 1))
  

# sim_bin_summ %>% 
#   ggplot(aes(x = gr, y = pct_rejected, colour = model, group = model)) +
#   geom_point() + 
#   geom_line() + 
#   geom_linerange(aes(x = gr,
#                      ymin = pct_rejected - 1.96*sd_rejected,
#                      ymax = pct_rejected + 1.96*sd_rejected)) +
#   theme_minimal() +
#   scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
#   guides(size = "none",
#          colour = "none") +
#   facet_grid(N~model) +
#     labs(y = "Proportion Null Rejected",
#        x = "Defier Proportion",
#        caption = "Note: Point size indicates number of draws in bin. \n 95% Confidence Intervals Displayed.",
#        title = "Power As a Function of Defier Proportion")
  

```

### Size Simulations




```{r size_sims}

run_sim <- FALSE
if (run_sim) {
  library(furrr)
  plan(multisession)
  
  simulations_size <- coef_list %>% 
    map(abs) %>% 
    future_map_dfr(simulation_func,
                   force_positive = TRUE,
                   .options = future_options(globals = c("sim_data",
                                                         "run_first_stage_interactions_fast",
                                                         "find_SEs",
                                                         "create_fake_data",
                                                         "simulation_func",
                                                         "power_test",
                                                         "sim_first_stage_forest"),
                                             packages = c("dplyr",
                                                          "modelr",
                                                          "margins",
                                                          "broom",
                                                          "grf")),
                   .progress = TRUE)
  
  
  
  plan(sequential)
  write.csv(simulations_size, file = "size_simulations_both.csv", row.names = FALSE)
  # write.csv(simulations_size, file = "size_simulations_both.csv", row.names = FALSE)  
} else {
  simulations_size <- readr::read_csv("size_simulations_both.csv")
}
simulations_size <- simulations_size %>% 
  mutate(model = tools::toTitleCase(model))
```

To address any concerns of multiple testing we now examine test size using simulations under the null hypothesis - where no defiers are present. Rather than simulate this for all three datasets I simply use the smallest in order to save on computational cost.

```{r}

simulations_size %>% 
  ggplot(aes(x = pval_defier,
             fill = model)) +
  geom_histogram(colour = "black") +
  facet_wrap(~model) +
  theme_minimal() +
  guides(fill = "none") +
  labs(x = "P-Value",
       title = "P-Value Distribution Under One-Sided Null")


simulations_size %>% 
  filter(pct_defiers_true == 0) %>% 
  ggplot(aes(sample = pval_defier,
             colour = model)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  scale_x_continuous(trans = negative_log_trans(10)) +
  facet_wrap(~model) +
  theme_minimal() +
  guides(colour = "none") +
  labs(title = "QQ plot of Simulated P-values",
       subtitle = "Negative Log(10) Scale")


simulations_size %>% 
  filter(pval_defier < 0.05) %>% 
  summarise(n = nrow(.),
            proportion = n / nrow(simulations_size))

simulations_size %>% 
  filter(pct_defiers_true > 0) %>% 
  nrow()
```


#### Romano-Wolf

# Data and Replication


## Angrist and Evans 1998

Describe Angrist and Evans paper and what a defier means in this context.

#### 1990 Census Data
```{r data_import}
library(haven)
library(dplyr)
library(broom)
df_90 <- read_sas("Angrist and Evans 90.sas7bdat")
```


Cleaning data according to Angrist and Evans SAS replication codes:
```{r data_cleaning}

clean_angrist_evans_data <- function(dataset){
  df_clean <- dataset %>% 
    filter((AGEM <= 35) & (AGEM >= 21)) %>% 
    filter(KIDCOUNT >= 2) %>% 
    filter(AGE2NDK >= 1) %>% 
    filter(AAGE == "0" & AAGE2ND == "0" & ASEX == "0" & ASEX2ND == "0") %>% 
    mutate(SEXK = as.numeric(SEXK),
           SEX2NDK = as.numeric(SEX2NDK),
           WEEK89D = as.numeric(WEEK89D),
           WEEK89M = as.numeric(WEEK89M),
           FERTIL = as.numeric(FERTIL)) %>% 
    mutate(fertdif = as.numeric(KIDCOUNT) - (FERTIL - 1),
           agefstm = as.numeric(AGEM) - as.numeric(AGEK)) %>% 
    filter(agefstm >= 15) %>% 
    filter(PWGTM1 > 0) %>% 
    mutate(samesex = (SEXK == SEX2NDK),
           morekids = (KIDCOUNT > 2)) %>% 
    rename_all(tolower)
  return(df_clean)
}
df_90_clean <- df_90 %>%
  clean_angrist_evans_data()
rm(df_90)
```

#### 1980 Census Data


```{r cleaning_1980}

df_80 <- read_sas("Angrist and Evans 80.sas7bdat")

df_80_clean <- df_80 %>%
    mutate(SEXK = as.numeric(SEXK),
         SEX2ND = as.numeric(SEX2ND),
         WEEKSD = as.numeric(WEEKSD),
         WEEKSM = as.numeric(WEEKSM),
         YOBM = as.numeric(YOBM),
         AGEQK = as.numeric(AGEQK),
         YOBD = 80 - as.numeric(AGED),
         YOBD = ifelse(QTRBTHD == 0, YOBD, YOBD - 1)) %>% 
  mutate(samesex = (SEXK == SEX2ND),
         morekids = (KIDCOUNT > 2),
         ageqm = 4*(80-YOBM) - as.numeric(QTRBTHM) - 1,
         ageqd = 4*(80 - YOBD) - as.numeric(QTRBKID),
         agefstm = round((ageqm-AGEQK)/4),
         agefstd = round((ageqd - AGEQK)/4),
         QTRMAR = as.numeric(QTRMAR),
         QTRBTHM = as.numeric(QTRBTHM),
         AGEMAR = as.numeric(AGEMAR),
         QTRBKID = as.numeric(QTRBKID),
         FERTIL = as.numeric(FERT)
         ) %>% 
  rename_all(tolower)




df_80_filtered <- df_80_clean %>% 
  filter((agem <= 35) & (agem >= 21)) %>% 
  filter(kidcount >= 2) %>%
  filter(ageq2nd > 4) %>% 
  filter(agefstm >= 15) %>%
  filter(agefstd >= 15 | is.na(agefstd)) %>%
  filter(asex == 0 &
         aage == 0 & 
         aqtrbrth == 0 &
         asex2nd == 0 &
         aage2nd == 0 &
         aqtrbrth == 0)



df_80_filtered_two <- df_80_filtered %>% 
  mutate(
         qtrmar = ifelse(qtrmar > 0, qtrmar - 1, qtrmar),
         yom = ifelse(qtrbthm <= qtrmar, yobm + agemar, yobm+agemar+1),
         dom_q = yom + (qtrmar/4),
         do1b_q = yobk + qtrbkid/4,
         illegit = ifelse(dom_q - do1b_q > 0, 1, 0)
         ) %>%  
  mutate(
         msample = ifelse(
           !is.na(aged) &
           timesmar == 1 &
           marital == 0 &
           illegit == 0 &
           agefstd >= 15 &
           agefstm >= 15,
           1, 0)
         ) %>% 
  filter(msample == 1)

######################

df_80_subset <- df_80_filtered_two %>% 
  rename(kid_age = agek,
         m_age = agem,
         d_age = aged) %>% 
  select(-starts_with("a")) %>% 
  mutate_at(c("racek",
              "birthplk",
              "schoolk",
              "state",
              "spanishm",
              "spanishd",
              "poverty"), factor) %>% 
  mutate_if(is.character, as.numeric)



df_80_final <- df_80_subset %>% 
  mutate(boy1st = (sexk == 0),
         boy2nd = (sex2nd == 0),
         boys2 = (sexk == 0) & (sex2nd == 0),
         girls2 = (sexk == 1) & (sex2nd == 1),
         samesex = boys2 | girls2,
         morekids = kidcount > 2,
         black_m = (racem == 2),
         hisp_m = (racem == 12),
         white_m = (racem == 01),
         other_race_m = 1 - black_m - hisp_m - white_m,
         black_d = (raced == 2),
         hisp_d = (raced == 12),
         white_d = (raced == 1),
         other_race_d = 1 - black_d - hisp_d - white_d,
         worked_m = (weeksm > 0),
         worked_d = (weeksd > 0),
         income_m = 2.099173554*(income1m + pmax(0, income2m)),
         income_d = (income1d + pmax(0, income2d)),
         fam_inc = pmax(faminc*2.099173554, 1),
         nonmoi = fam_inc - income1m*2.099173554,
         nonmomil = log(pmax(1, nonmoi)))
rm(df_80,
   df_80_clean,
   df_80_filtered,
   df_80_filtered_two,
   df_80_subset)

```



## Replicating Results

```{r data_transforming}

transform_clean_angrist_evans <- function(dataset) {
  transformed_df <- dataset %>%
    rename(
      kid_age = agek,
      kid2_age = age2ndk,
      m_age = agem,
      d_age = aged
    ) %>%
    select(-starts_with("a")) %>%
    mutate_at(c(
      "racek",
      "birthplk",
      "schoolk",
      "state",
      "hispm",
      "hispd",
      "poverty",
      "pobm",
      "hispd",
      "pobd",
      "hispk"
    ), factor) %>%
    mutate_if(is.character, as.numeric) %>%
    mutate(
      boy1st = (sexk == 0),
      boy2nd = (sex2ndk == 0),
      boys2 = (sexk == 0) & (sex2ndk == 0),
      girls2 = (sexk == 1) & (sex2ndk == 1),
      samesex = boys2 | girls2,
      morekids = kidcount > 2,
      black_m = (racem == 2),
      hisp_m = (racem == 12),
      white_m = (racem == 01),
      other_race_m = 1 - black_m - hisp_m - white_m,
      black_d = (raced == 2),
      hisp_d = (raced == 12),
      white_d = (raced == 1),
      other_race_d = 1 - black_d - hisp_d - white_d,
      worked_m = (week89m > 0),
      worked_d = (week89d > 0)
    )

  return(transformed_df)
}

df_90_subset <- df_90_clean %>%
  transform_clean_angrist_evans()

  
  
  
df_90_final <- df_90_subset %>% 
  mutate(
         income_m = 1.2883*(incomem1 + pmax(0, incomem2)),
         income_d = (incomed1 + pmax(0, incomed2)),
         fam_inc = pmax(faminc*1.2883, 1),
         nonmoi = fam_inc - incomem1*1.2883,
         nonmomil = log(pmax(1, nonmoi))
  )

rm(df_90_clean, df_90_subset)
```


#### Table Two Summary Statistics

Trying to recreate table 2
```{r table_2}
library(tidyr)
AE_90_summary <- df_90_final %>% 
  summarise(children_ever_born = mean(fertil - 1),
            more_than_2 = mean(morekids),
            mean_boy_first = mean(boy1st),
            boy_2nd = mean(boy2nd),
            two_boys = mean(boys2),
            two_girls = mean(girls2),
            samesex = mean(samesex),
            age = mean(m_age),
            worked = mean(worked_m),
            weeks = mean(week89m),
            hrs_wk = mean(hour89m),
            labour_income_mum = mean(income_m),
            labour_income_dad = mean(income_d, na.rm = TRUE),
            fam_income = mean(fam_inc),
            mean_non_wife = mean(nonmoi)) %>% 
  gather(term, mean_90) 

AE_80_summary <- df_80_final %>% 
    summarise(children_ever_born = mean(fertil - 1),
            more_than_2 = mean(morekids),
            mean_boy_first = mean(boy1st),
            boy_2nd = mean(boy2nd),
            two_boys = mean(boys2),
            two_girls = mean(girls2),
            samesex = mean(samesex),
            age = mean(m_age),
            worked = mean(worked_m),
            weeks = mean(weeksm),
            hrs_wk = mean(hoursm),
            labour_income_mum = mean(income_m),
            labour_income_dad = mean(income_d, na.rm = TRUE),
            fam_income = mean(fam_inc),
            mean_non_wife = mean(nonmoi)) %>% 
  gather(term, mean_80) 

AE_summary <- inner_join(AE_80_summary, AE_90_summary, by = "term") %>% 
  knitr::kable(digits = 3)
AE_summary

```

#### Regression Results

Recreating Table 5
```{r table_5, results = "asis"}
library(AER)
library(stargazer)
library(purrr)
table_5_models_90 <- c("worked_m",
  "week89m",
  "hour89m",
  "income_m",
  "log(fam_inc)") %>%
  map(~(
  paste0(., " ~ morekids | samesex") %>% 
  as.formula() %>% 
  ivreg(., data = df_90_final)))

table_5_models_80 <- c("worked_m",
  "weeksm",
  "hoursm",
  "income_m",
  "log(fam_inc)") %>% 
  map(~(
  paste0(., " ~ morekids | samesex") %>% 
  as.formula() %>% 
  ivreg(., data = df_80_final)))

stargazer(table_5_models_80,
          omit = "Constant",
          title = "WALD ESTIMATES OF LABOR-SUPPLY MODELS 1980 DATA - REPLICATED",header = FALSE,type = "html",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"))

stargazer(table_5_models_90,
          omit = "Constant",
          title = "WALD ESTIMATES OF LABOR-SUPPLY MODELS 1990 DATA - REPLICATED",header = FALSE,type = "html",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"))





rm(table_5_models_80,
   table_5_models_90)
``` 



Now table 6
```{r table_6, results = "asis"}
create_model_formula <- function(dependent_var){
  model <- as.formula(paste0(dependent_var, "~ morekids + m_age + boy1st + boy2nd + black_m + hisp_m + other_race_m | samesex +  m_age + boy1st + boy2nd + black_m + hisp_m + other_race_m"))
  return(model)
}

table_6_models_80 <- c("worked_m",
  "weeksm",
  "hoursm",
  "income_m",
  "log(fam_inc)") %>% 
  map(~(create_model_formula(.) %>% 
          ivreg(data = df_80_final)))
  

table_6_models_90 <- c("worked_m",
                    "week89m",
                    "hour89m",
                    "income_m",
                    "log(fam_inc)") %>% 
  map(~(create_model_formula(.) %>% 
          ivreg(data = df_90_final)))

stargazer(table_6_models_80,
          keep = "morekidsTRUE",
          title = "2SLS ESTIMATES OF LABOR-SUPPLY MODELS USING 1980 CENSUS DATA - REPLICATION",
          notes = "Age at first birth omitted since I can't seem to find it.",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"),
          type = "html")

stargazer(table_6_models_90, keep = "morekidsTRUE",
          title = "2SLS ESTIMATES OF LABOR-SUPPLY MODELS USING 1990 CENSUS DATA - REPLICATION",
          notes = "Age at first birth omitted since I can't seem to find it.",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"),
          type = "html")
rm(table_6_models_80, table_6_models_90)
```



## Maimonides Rule


Mention somewhere HAC instead of moulton factor adjustment - only makes a large difference in the discontinuity sample.

#### Cleaning Grade 5
```{r maimonides_grade_5}
clean_maimonides_data <- function(dataset){
  clean_df <- dataset %>%
    mutate(
      avgverb = ifelse(avgverb > 100, avgverb - 100, avgverb),
      avgmath = ifelse(avgmath > 100, avgmath - 100, avgmath),
      func1 = c_size/(as.integer((c_size-1)/40)+1),
      func2 = cohsize/(as.integer(cohsize/40)+1),
      avgverb = ifelse(verbsize == 0, NA, avgverb),
      passverb = ifelse(verbsize == 0, NA, passverb),
      avgmath = ifelse(mathsize == 0, NA, avgmath),
      passmath = ifelse(mathsize == 0, NA, avgmath),
      disc = (c_size >= 36 & c_size <= 45) | 
             (c_size >= 76 & c_size <= 85) |
             (c_size >= 116 & c_size <= 125),
      all = 1,
      c_size_squared = (c_size^2)/100,
      trend = ifelse(c_size >= 0 & c_size <= 40, c_size, NA),
      trend = ifelse(c_size >= 41 & c_size <= 80, 20 + (c_size/2), trend),
      trend = ifelse(c_size >= 81 & c_size <= 120, (100/3) + (c_size/3), trend),
      trend = ifelse(c_size >= 121 & c_size <= 160, (130/3) + (c_size/4), trend)
    ) %>% 
    filter(
      classize > 1 & classize < 45 & c_size > 5
    ) %>% 
    filter(
      c_leom == 1 & c_pik < 3
    )
  return(clean_df)
  
}
df_final5_cleaned <- read_dta("Angrist and Lavy Grade 5.dta") %>% 
  clean_maimonides_data()

##do stuff


```


#### Cleaning Grade 4
```{r maimonides_grade_4}
df_final4_cleaned <- read_dta("Angrist and Lavy Grade 4.dta") %>% 
  clean_maimonides_data()

```


## Replicating OLS 
```{r replicating_maimonides, results = "asis"}
## Grade 5
col_1 <- lm(avgverb ~ classize, data = df_final5_cleaned)
col_2 <- lm(avgverb ~ classize + tipuach, data = df_final5_cleaned)
col_3 <- lm(avgverb ~ classize + tipuach + c_size, data = df_final5_cleaned)
col_4 <- lm(avgmath ~ classize, data = df_final5_cleaned)
col_5 <- lm(avgmath ~ classize + tipuach, data = df_final5_cleaned)
col_6 <- lm(avgmath ~ classize + tipuach + c_size, data = df_final5_cleaned)
## Grade 4
col_7 <- lm(avgverb ~ classize, data = df_final4_cleaned)
col_8 <- lm(avgverb ~ classize + tipuach, data = df_final4_cleaned)
col_9 <- lm(avgverb ~ classize + tipuach + c_size, data = df_final4_cleaned)
col_10 <- lm(avgmath ~ classize, data = df_final4_cleaned)
col_11 <- lm(avgmath ~ classize + tipuach, data = df_final4_cleaned)
col_12 <- lm(avgmath ~ classize + tipuach + c_size, data = df_final4_cleaned)

SEs <- list(col_1,
            col_2,
            col_3,
            col_4,
            col_5,
            col_6,
            col_7,
            col_8,
            col_9,
            col_10,
            col_11,
            col_12) %>% 
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))

stargazer(col_1,
          col_2,
          col_3,
          col_4,
          col_5,
          col_6,
          col_7,
          col_8,
          col_9,
          col_10,
          col_11,
          col_12,
          se = SEs,
          omit.table.layout = "sn",
          type = "html",
          omit = "Constant",
          dep.var.labels = c("English Comprehension",
                             "Maths",
                             "English Comprehension",
                             "Maths"),
          column.labels = c("Grade 5",
                            "Grade 4"),
          column.separate = c(6, 6),
          initial.zero = FALSE,
          notes = "HAC standard errors used instead of Moulton factor adjustment.")
rm(col_1,
   col_2,
   col_3,
   col_4,
   col_5,
   col_6,
   col_7,
   col_8,
   col_9,
   col_10,
   col_11,
   col_12
   )
```


## Replicating IV
```{r maimonides_IV, results = "asis"}

## Grade 5


iv_maim_verb_full_5 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned)
iv_maim_math_full_5 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned)

iv_maim_verb_disc_5 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned %>% filter(disc == 1))
iv_maim_math_disc_5 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned %>% filter(disc == 1))


## Grade 4

iv_maim_verb_full_4 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned)
iv_maim_math_full_4 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned)

iv_maim_verb_disc_4 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned %>% filter(disc == 1))
iv_maim_math_disc_4 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned %>% filter(disc == 1))




SEs_IV_5 <- list(
  iv_maim_verb_full_5,
  iv_maim_math_full_5,
  iv_maim_verb_disc_5,
  iv_maim_math_disc_5
) %>%
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))
stargazer(iv_maim_verb_full_5,
          iv_maim_math_full_5,
          iv_maim_verb_disc_5,
          iv_maim_math_disc_5,
          se = SEs_IV_5,
          column.labels = c("Full Sample", "Discontinuity Sample"),
          column.separate = c(2, 2),
          type = "html",
          title = "IV Maimonides Rule Fifth Grade",
          notes = "HAC standard errors used instead of Moulton factor adjustment.")



SEs_IV_4 <- list(
  iv_maim_verb_full_4,
  iv_maim_math_full_4,
  iv_maim_verb_disc_4,
  iv_maim_math_disc_4
) %>%
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))
stargazer(iv_maim_verb_full_4,
          iv_maim_math_full_4,
          iv_maim_verb_disc_4,
          iv_maim_math_disc_4,
          se = SEs_IV_4,
          column.labels = c("Full Sample", "Discontinuity Sample"),
          column.separate = c(2, 2),
          type = "html",
          title = "IV Maimonides Rule Fourth Grade",
          notes = "HAC standard errors used instead of Moulton factor adjustment.")

rm(SEs_IV_4,
   SEs_IV_5,
   SEs,
   iv_maim_math_disc_4,
   iv_maim_math_full_4,
   iv_maim_verb_disc_4,
   iv_maim_verb_full_4,
   iv_maim_math_disc_5,
   iv_maim_math_full_5,
   iv_maim_verb_disc_5,
   iv_maim_verb_full_5)

```


# Checking First Stage

## Angrist and Evans
```{r run_first_stage_AE}

AE_data_80 <- df_80_final %>% 
  select(
    samesex,
    morekids,
    black_m,
    hisp_m,
    other_race_m,
    black_d,
    hisp_d,
    other_race_d,
    gradem,
    graded,
    m_age,
    d_age
  ) %>% 
  na.omit()

AE_data_90 <- df_90_final %>% 
  select(samesex,
         morekids,
         black_m,
         hisp_m,
         other_race_m,
         black_d,
         hisp_d,
         other_race_d,
         yearschm,
         yearschd, 
         m_age,
         d_age,
         pwgtm1,
         pwgtd1) %>% 
  na.omit()





first_stage_interactions_80 <- AE_data_80 %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "morekids",
                                    instrument = "samesex") %>% 
  mutate(dataset = "1980") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm,  dataset, dydx_lo, dydx_hi)
first_stage_interactions_90 <- AE_data_90 %>% 
  run_first_stage_interactions_fast(dataset = .,
                                   dependent_variable = "morekids",
                                   instrument = "samesex") %>% 
  mutate(dataset = "1990") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm, dataset, dydx_lo, dydx_hi)

first_stage_interactions_AE <- bind_rows(first_stage_interactions_90, first_stage_interactions_80) 



```


testing old stuff
```{r old_stuff, eval = FALSE, echo = FALSE}

run_first_stage_interactions_fast_slow_SE <- function(dataset, dependent_variable, instrument){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula)
  degrees_freedom <- first_stage_fit$df.residual
  dydx_margins <- dydx(data = dataset,
                       model = first_stage_fit,
                       variable = "instrument") %>% pull()
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    distinct() %>% 
    mutate(instrument = TRUE)
  first_stage_margins <- dydx(model = first_stage_fit, data = dataset_unique, variable = "instrument") 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins$SE_dydx_instrument <- find_SEs_slow(dataset_unique, vcov(first_stage_fit), instrument)
  
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom))
  return(df_margins)
}

find_SEs_slow <- function(model_data_no_y, model_vcov, instrument){
  model_data_no_y <- model_data_no_y %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0("~", "instrument", "*."))
  
  model_matrix <- model_data_no_y %>% 
    mutate(instrument = 1) %>% 
    model.matrix(model_formula, data = .)
  
  gradient_matrix_kinda <- model_matrix %>%
    as_tibble() %>% 
    distinct() %>% 
  mutate_at(vars(-contains(":")), ~(. = 0)) %>% 
    mutate(instrument = 1) %>% 
  as.matrix()
  
  vcov_dydx_intermediate <- Rfast::mat.mult(gradient_matrix_kinda, model_vcov)
  vcov_dydx <- Rfast::mat.mult(vcov_dydx_intermediate, Rfast::transpose(gradient_matrix_kinda))
  SE_dydx <- sqrt(diag(vcov_dydx))
  return(SE_dydx)
    
} 


run_first_stage_interactions_slow <- function(dataset, dependent_variable, instrument){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula)
  degrees_freedom <- first_stage_fit$df.residual
  dydx_margins <- dydx(data = dataset,
                       model = first_stage_fit,
                       variable = "instrument") %>% pull()
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    distinct() %>% 
    mutate(instrument = TRUE)
  first_stage_margins <- margins(first_stage_fit, data = dataset_unique, variables = "instrument", unit_ses = TRUE) 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom))
  return(df_margins)
}



test <- test_data %>% 
  run_first_stage_interactions_fast_slow_SE(dataset = ., 
                                    dependent_variable = "morekids",
                                    instrument = "samesex")

all_equal(first_stage_interactions, test)
```



```{r plotting_first_stage_interactions}

first_stage_interactions_AE %>% 
  filter(pval_one_neg < 0.1 | pval_holm < 0.1)

colour_pair <- c("hotpink", "darkorange")

first_stage_interactions_AE %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram(colour = "black") +
  facet_wrap(~dataset, scales = "free") +
  theme_minimal() +
  guides(fill = "none") +
  scale_fill_manual(values = colour_pair) +
  labs(x = "Instrument Partial Effect",
       title = "Partial Effects - Same-Sex Instrument")




first_stage_interactions_AE %>% 
  group_by(dataset) %>% 
  sample_n(10000) %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  facet_wrap(~dataset, scales = "free_x") +
  geom_hline(yintercept = 0, linetype = "longdash") +
  guides(colour = "none") +
  scale_colour_manual(values = colour_pair) +
  labs(y = "Instrument Partial Effect",
       title = "Partial Effects Ranked - Same-Sex Instrument")


```



```{r plotting_interactions_two}

first_stage_interactions_AE %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram(colour = "black") +
  facet_wrap(~dataset, scales = "free") +
  theme_minimal() +
  scale_fill_manual(values = colour_pair) +
  guides(fill = "none") +
  labs(x = "P-Value Defier",
       title = "Histogram of One-Sided P-Values - Same-Sex Instrument")

first_stage_interactions_AE %>% 
  group_by(dataset) %>% 
  sample_n(10000) %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values - Same-Sex Instrument",
       caption = "Note: Both axes use negative log(10) scale.") +
  facet_wrap(~dataset) +
  guides(colour = "none") +
  scale_colour_manual(values = colour_pair)




```

## Maimonides Rule


```{r maim_FS}
first_stage_interactions_maim_5 <- df_final5_cleaned %>% 
  select(classize,
         tipuach,
         c_size,
         c_size_squared,
         func1) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "classize",
                                    instrument = "func1") %>% 
  mutate(dataset = "Fifth Grade") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm,  dataset, dydx_lo, dydx_hi)

first_stage_interactions_maim_4 <- df_final4_cleaned %>% 
  select(classize,
         tipuach,
         c_size,
         c_size_squared,
         func1) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                   dependent_variable = "classize",
                                   instrument = "func1") %>% 
  mutate(dataset = "Fourth Grade") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm, dataset, dydx_lo, dydx_hi)

first_stage_interactions_maimonides <- bind_rows(first_stage_interactions_maim_5, first_stage_interactions_maim_4) 
```



```{r maim_plot}

first_stage_interactions_maimonides %>% 
  filter(pval_one_neg < 0.1 | pval_holm < 0.1)

first_stage_interactions_maimonides %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram(colour = "black") +
  facet_wrap(~dataset, scales = "free") +
  theme_minimal() +
  guides(fill = "none") +
  scale_fill_manual(values = colour_pair) +
  labs(x = "Instrument Partial Effects",
       title = "Partial Effects - Maimonides' Instrument")

first_stage_interactions_maimonides %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram(colour="black") +
  facet_wrap(~dataset, scales = "free") +
  guides(fill = "none") +
  theme_minimal() +
  labs(title = "P-Values - Maimonides' Instrument",
       x = "P-Value") +
  scale_fill_manual(values = colour_pair)

first_stage_interactions_maimonides %>% 
  group_by(dataset) %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  facet_wrap(~dataset, scales = "free_x") +
  geom_hline(yintercept = 0, linetype = "longdash") +
  labs(y = "Partial Effect",
       title = "Partial Effect Ranked - Maimonides' Instrument") +
  scale_colour_manual(values = colour_pair) +
  guides(colour = "none")

first_stage_interactions_maimonides %>% 
  group_by(dataset) %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values - Maimonides' Instrument",
       caption = "Note: Both axes negative log(10) scale.") +
  facet_wrap(~dataset) +
  scale_colour_manual(values = colour_pair) +
  guides(colour = "none")

```

## Autor Dorn Hanson

```{r adh_fs}
df_china <- read_dta("Autor Dorn and Hanson China.dta")
first_stage_interactions_ADH_manu <- df_china %>% 
  select(d_sh_empl_mfg,
         d_tradeusch_pw,
         d_tradeotch_pw_lag,
         l_shind_manuf_cbp,
         starts_with("reg"),
         l_sh_popedu_c,
         l_sh_popfborn,
         l_sh_empl_f,
         l_sh_routine33,
         l_task_outsource,
         t2) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "d_tradeusch_pw",
                                    instrument = "d_tradeotch_pw_lag",
                                    weights = df_china$timepwt48) %>% 
  mutate(dataset = "only")


```



```{r ADH_plot}
first_stage_interactions_ADH_manu %>% nrow()

first_stage_interactions_ADH_manu %>% 
  filter(pval_holm < 0.05)


first_stage_interactions_ADH_manu %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram(colour = "black") +
  guides(fill = "none") +
  scale_fill_manual(values = colour_pair) +
  theme_minimal() +
  labs(x = "Instrument Partial Effects",
       title = "Partial Effects - Bartik Instrument")

first_stage_interactions_ADH_manu %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram(colour = "black") +
  scale_fill_manual(values = colour_pair) +
  labs(x = "P-Value",
       title = "P-Values - Bartik Instrument") +
  theme_minimal()

first_stage_interactions_ADH_manu %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  scale_colour_manual(values = colour_pair) +
  labs(title = "Partial Effects Ranked - Bartik Instrument",
       y = "Partial Effect") +
  guides(colour = "none")

first_stage_interactions_ADH_manu %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values - Bartik Instrument",
       caption = "Note: Both axes use negative log(10) scale.") +
  guides(colour = "none")
```


# Random Forest


Write up about methodology and simulation performance

## Angrist and Evans

```{r random_forest_run}
library(grf)
N_obs <- 10000
df_rf_AE_80 <- AE_data_80 %>% 
  sample_n(N_obs)

X_matrix_AE_80 <- df_rf_AE_80 %>% 
  select(-samesex, -morekids) %>% 
  as.matrix()

forest_first_stage_AE_80 <- causal_forest(X = X_matrix_AE_80,
                                    Y = df_rf_AE_80$morekids,
                                    W = df_rf_AE_80$samesex,
                                    num.trees = 4000) 
tau_hat_oob_AE_80 <- predict(forest_first_stage_AE_80, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "1980")

## Now 90s

df_rf_AE_90 <- AE_data_90 %>% 
  sample_n(N_obs)

X_matrix_AE_90 <- df_rf_AE_90 %>% 
  select(-samesex, -morekids) %>% 
  as.matrix()

forest_first_stage_AE_90 <- causal_forest(X = X_matrix_AE_90,
                                          Y = df_rf_AE_90$morekids,
                                          W = df_rf_AE_80$samesex,
                                          num.trees = 4000)
tau_hat_oob_AE_90 <- predict(forest_first_stage_AE_90, estimate.variance = TRUE) %>% 
  as_tibble() %>% 
  mutate(dataset = "1990")

tau_hat_oob_AE <- bind_rows(tau_hat_oob_AE_90,
                            tau_hat_oob_AE_80)


```

```{r random_forest_plots}


ggplot(tau_hat_oob_AE,
       aes(x = predictions,
           fill = dataset)) +
  geom_histogram(colour = "black") +
  facet_wrap(~dataset) +
  scale_fill_manual(values = colour_pair) +
  labs(x = "Heterogeneous Effects",
       title = "Heterogeneous Effects - Same-Sex Instrument") +
  theme_minimal() +
  guides(fill = "none")

tau_hat_results <- tau_hat_oob_AE %>%
  group_by(dataset) %>% 
  arrange(predictions) %>% 
  mutate(sigma_hat = sqrt(variance.estimates),
         prediction_lo = predictions - 1.96*sigma_hat,
         prediction_hi = predictions + 1.96*sigma_hat,
         t_stat = predictions / sigma_hat,
         critical_value = qt(0.95, N_obs - 13, lower.tail = FALSE),
         pval = pt(t_stat, df = N_obs - 13),
         pval_holm = p.adjust(pval, method = "holm"),
         reject_H0 = ifelse(pval_holm < 0.05, 1, 0),
         rank = row_number())

tau_hat_results %>% 
  ggplot(aes(x = rank, y = predictions, ymin = prediction_lo, ymax = prediction_hi)) + 
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.1) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  facet_wrap(~dataset) +
  scale_colour_manual(values = colour_pair) +
  labs(y = "Heterogeneous Effects",
       title = "Heterogeneous Effects Ranked - Same-Sex Instrument") +
  guides(colour = "none")

tau_hat_results %>% 
  filter(reject_H0 == 1) 


tau_hat_results %>% 
  ggplot(aes(sample = pval, colour = dataset)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values",
       caption = "Note: Both axes use negative log(10) scale.") +
  facet_wrap(~dataset) +
  scale_colour_manual(values = colour_pair) +
  guides(colour = "none",
         fill = "none")
  
```


## Maimonides Rule



```{r rf_run_maimonides}

X_matrix_maim_5 <- df_final5_cleaned %>% 
  select(
         tipuach,
         c_size,
         c_size_squared) %>% 
  as.matrix()

forest_first_stage_maim_5 <- causal_forest(X = X_matrix_maim_5,
                                    Y = df_final5_cleaned$classize,
                                    W = df_final5_cleaned$func1,
                                    num.trees = 4000) 
tau_hat_oob_maim_5 <- predict(forest_first_stage_maim_5, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "Fifth Grade")

## Now fourth grade


X_matrix_maim_4 <- df_final4_cleaned %>% 
  select(
         tipuach,
         c_size,
         c_size_squared) %>% 
  as.matrix()

forest_first_stage_maim_4 <- causal_forest(X = X_matrix_maim_4,
                                    Y = df_final4_cleaned$classize,
                                    W = df_final4_cleaned$func1,
                                    num.trees = 4000) 
tau_hat_oob_maim_4 <- predict(forest_first_stage_maim_4, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "Fourth Grade")


tau_hat_oob_maimonides <- bind_rows(tau_hat_oob_maim_5,
                                    tau_hat_oob_maim_4)
```



```{r rf_plot_maimonides}
ggplot(tau_hat_oob_maimonides,
       aes(x = predictions,
           fill = dataset)) +
  geom_histogram(colour = "black") +
  facet_wrap(~dataset) +
  scale_fill_manual(values = colour_pair) +
  labs(x = "Heterogeneous Effects",
       title = "Heterogeneous Effects - Maimonides' Instrument") +
  theme_minimal() +
  guides(fill = "none")

tau_hat_results_maimonides <- tau_hat_oob_maimonides %>%
  group_by(dataset) %>% 
  arrange(predictions) %>% 
  mutate(sigma_hat = sqrt(variance.estimates),
         prediction_lo = predictions - 1.96*sigma_hat,
         prediction_hi = predictions + 1.96*sigma_hat,
         t_stat = predictions / sigma_hat,
         critical_value = qt(0.95, N_obs - 13, lower.tail = FALSE),
         pval = pt(t_stat, df = N_obs - 13),
         pval_holm = p.adjust(pval, method = "holm"),
         reject_H0 = ifelse(pval_holm < 0.05, 1, 0),
         rank = row_number())

tau_hat_results_maimonides %>% 
  ggplot(aes(x = rank,
             y = predictions,
             ymin = prediction_lo,
             ymax = prediction_hi)) + 
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.1) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  facet_wrap(~dataset) +
  scale_colour_manual(values = colour_pair) +
  labs(y = "Heterogeneous Effects Ranked - Maimonides' Instrument") +
  guides(colour = "none",
         fill = "none")

tau_hat_results_maimonides %>% 
  filter(reject_H0 == 1) 


tau_hat_results_maimonides %>% 
  ggplot(aes(sample = pval, colour = dataset)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values - Maimonides' Rule",
       caption = "Note: Both axes use negative log(10) scale.") +
  facet_wrap(~dataset) +
  scale_colour_manual(values = colour_pair) +
  guides(colour = "none",
         fill = "none")
```

## Autor Dorn Hanson
```{r ADH_rf}

ADH_matrix <- df_china %>% 
  select(d_sh_empl_mfg,
         l_shind_manuf_cbp,
         starts_with("reg"),
         l_sh_popedu_c,
         l_sh_popfborn,
         l_sh_empl_f,
         l_sh_routine33,
         l_task_outsource,
         t2) %>% 
  as.matrix()



forest_first_stage_ADH <- causal_forest(X = ADH_matrix,
                                        Y = df_china$d_tradeusch_pw,
                                        W = df_china$d_tradeotch_pw_lag,
                                        num.trees = 4000)

tau_hat_oob_ADH <- predict(forest_first_stage_ADH, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "ADH")

```






```{r ADH_rf_plot}

ggplot(tau_hat_oob_ADH,
       aes(x = predictions, fill = dataset)) +
  geom_histogram(colour = "black") +
  scale_fill_manual(values = colour_pair) +
  labs(x = "Heterogeneous Effects",
       title = "Heterogeneous Effects - Bartik Instrument") +
  theme_minimal() +
  guides(fill = "none")

tau_hat_results_ADH <- tau_hat_oob_ADH %>%
  arrange(predictions) %>% 
  mutate(sigma_hat = sqrt(variance.estimates),
         prediction_lo = predictions - 1.96*sigma_hat,
         prediction_hi = predictions + 1.96*sigma_hat,
         t_stat = predictions / sigma_hat,
         critical_value = qt(0.95, N_obs - 13, lower.tail = FALSE),
         pval = pt(t_stat, df = N_obs - 13),
         pval_holm = p.adjust(pval, method = "holm"),
         reject_H0 = ifelse(pval_holm < 0.05, 1, 0),
         rank = row_number())

tau_hat_results_ADH %>% 
  ggplot(aes(x = rank, y = predictions, ymin = prediction_lo, ymax = prediction_hi)) + 
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.1) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  scale_colour_manual(values = colour_pair) +
  labs(y = "Heterogeneous Effects",
       title = "Heterogeneous Effects Ranked - Bartik Instrument") +
  guides(colour = "none",
         fill = "none")

tau_hat_results_ADH %>% 
  ggplot(aes(sample = pval, colour = dataset)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values - Bartik Instrument",
       caption = "Note: Both axes use negative log(10) scale.") +
  guides(colour = "none",
         fill = "none") +
  scale_colour_manual(values = colour_pair)
```


# Bayesian Test
write up on bayesian test

## Angrist and Evans
## Maimonides Rule
## Autor Dorn Hanson

# Conclusion

# Appendix

```{r p_value_normal_scale_plot_appendix}
simulations_power <- readr::read_csv("C:/Users/edjee/Dropbox/Ed/power_simulations_both_medium.csv") %>% 
  mutate(model = tools::toTitleCase(model))

library(scales)
negative_log_trans <- function(base = exp(1)) {
  trans <- function(x) -log(x, base)
  inv <- function(x) base^(-x)
  trans_new(paste0("negative_log-", format(base)), trans, inv, 
            log_breaks(base = base), 
            domain = c(1e-100, Inf))
}

## Remove this one
simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15) +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  guides(colour = "none") +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  facet_wrap(~model) +
  labs(x = "Defier Percentage",
       y = "P-Value",
       caption = "Note: Dashed line indicates a p-value of 0.05.",
       title = "P-Values from Power Simulations") +
  theme_minimal()


simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15) +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  guides(colour = "none") +
  scale_y_reverse() +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  facet_wrap(~model) +
  labs(x = "Defier Percentage",
       y = "P-Value",
       caption = "Note: Y-axis scale inverted. \n Dashed line indicates a p-value of 0.05.",
       title = "P-Values from Power Simulations") +
  theme_minimal()
```


```{r p_val_power_neg_log_10_appendix}

simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15) +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(colour = "none") +
  theme_minimal() +
  facet_wrap(~model) +
  labs(x = "Defier Percentage",
       y = "P-Value",
       caption = "Note: Y-Axis on negative log(10) scale. \n Dashed line indicates a p-value of 0.05",
       title = "P-Values from Power Simulations")

```

```{r p_val_low_defier_plot_appendix}
simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15,
             aes(colour = model)) +
  geom_hline(yintercept = 0.05, linetype = "longdash") +
  scale_y_reverse() +
  geom_smooth(se = TRUE,
              colour = "violetred",
              alpha = 0.5) +
  scale_x_continuous(limits = c(0, 0.2), labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  facet_wrap(~model) +
  guides(colour = "none") +
  labs(x = "Defier Percentage",
       y = "P-Value",
       title = "Power Simulation Results at Low Defier Proportion",
       caption = "Note: Y-axis scale inverted. \n Dashed line indicates a p-value of 0.05.")

simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = pct_defiers_true,
             y = pval_defier,
             colour = model)) +
  geom_point(alpha = 0.15,
             aes(colour = model)) +
  geom_hline(yintercept = 0.05, linetype = "longdash") +
  geom_smooth(se = TRUE,
              colour = "violetred",
              alpha = 0.5) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  scale_x_continuous(limits = c(0, 0.2), labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  facet_wrap(~model) +
  guides(colour = "none") +
  labs(x = "Defier Percentage",
       y = "P-Value",
       title = "Power Simulation Results at Low Defier Proportion",
       caption = "Note: Y-Axis on negative log(10) scale. \n Dashed line indicates a p-value of 0.05")

```


```{r demonstration_plot_appendix}
# REMOVE this one
p <- simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = mean_dydx,
             y = pval_defier)) +
  geom_point(alpha = 0.05) +
  geom_smooth(method = lm, se = FALSE) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  theme_minimal() +
  guides(colour = "none") +
  labs(x = "Mean Instrument Partial Effect",
       y = "P-Value",
       title = "Defier P-Value against Mean Instrument Partial Effect",
       caption = "Note: Y-Axis on negative log(10) scale.")
ggMarginal(p,  type = "histogram")
```


```{r mean_dydx_plot_appendix}


p <- simulations_power %>% 
  filter(pct_defiers_true > 0) %>% 
  ggplot(aes(x = mean_dydx,
             y = pval_defier,
             colour = factor(sign(estimate)),
             group = sign(estimate))) +
  geom_point(alpha = 0.05) +
  geom_smooth(method = lm, se = FALSE) +
  scale_y_continuous(trans = negative_log_trans(10)) +
  theme_minimal() +
  guides(colour = "none") +
  labs(x = "Mean Instrument Partial Effect",
       y = "P-Value",
       title = "Defier P-Value against Mean Instrument Partial Effect",
       caption = "Note: Y-Axis on negative log(10) scale.")
ggMarginal(p,
           type = "histogram",
           groupColour = TRUE,
           groupFill = TRUE)


```


```{r binned_power_appendix}
sim_bin <- simulations_power %>% 
  group_by(model,
           gr=cut(pct_defiers_true, breaks= seq(0, 1, by = 0.05))) %>% 
  mutate(n= n()) %>%
  arrange(as.numeric(gr)) %>% 
  mutate(n_rejected = ifelse(pval_defier < 0.05, 1, 0)) %>% 
  mutate(pct_rejected = sum(n_rejected)/n) 

sim_bin_summ <- simulations_power %>% 
  group_by(model,
           gr=cut(pct_defiers_true, breaks= seq(0, 1, by = 0.05))) %>% 
  mutate(n= n()) %>%
  arrange(as.numeric(gr)) %>% 
  mutate(n_rejected = ifelse(pval_defier < 0.05, 1, 0)) %>% 
  summarise(pct_rejected = mean(n_rejected),
            sd_rejected = sd(n_rejected),
            n = unique(n),
            mean_true_defier = mean(pct_defiers_true))


sim_bin_summ %>% 
  na.omit() %>% 
  ggplot(aes(x = gr, y = pct_rejected, colour = model, group = model)) +
  geom_point(aes(size = n)) + 
  geom_line() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(size = "none")  +
  theme(legend.position = c(0.5, 0.2),
        legend.background = element_rect(fill="lightgrey", 
                                  size=0.5,  linetype = 0)) +
  labs(y = "Proportion Null Rejected",
       x = "Defier Proportion",
       caption = "Note: Point size indicates number of draws in bin.",
       title = "Power As a Function of Defier Proportion")

sim_bin_summ %>%
  na.omit() %>%
  filter(mean_true_defier < 0.3) %>%
  ggplot(aes(x = gr, y = pct_rejected, colour = model, group = model)) +
  geom_point(aes(size = n)) +
  geom_line() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(size = "none") +
    theme(legend.position = c(0.5, 0.2),
        legend.background = element_rect(fill="lightgrey",
                                  size=0.5,  linetype = 0)) +
    labs(y = "Proportion Null Rejected",
       x = "Defier Proportion",
       caption = "Note: Point size indicates number of draws in bin.",
       title = "Power As a Function of Defier Proportion")




sim_bin %>% 
  na.omit() %>% 
  summarise(m_pval = mean(pval_defier),
         sd_pval = sd(pval_defier)) %>% 
  ggplot(aes(x = gr, y = m_pval, colour = model, group = model)) +
  geom_point() + 
  geom_line() + 
  geom_linerange(aes(x = gr,
                     ymin = m_pval - 1.96*sd_pval,
                     ymax = m_pval + 1.96*sd_pval)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(size = "none",
         colour = "none") +
  facet_wrap(~model) +
    labs(y = "Mean P-Value",
       x = "Defier Proportion",
       caption = "Note: Dashed line indicates p-value of 0.05. \n 95% Confidence Intervals Displayed.",
       title = "Mean P-Value as a Function of Defier Proportion") +
  geom_hline(yintercept = 0.05,
             linetype = "longdash",
             alpha = 0.5) 

sim_bin_summ %>% 
  na.omit() %>% 
  ggplot(aes(x = gr, y = pct_rejected, colour = model, group = model)) +
  geom_point() + 
  geom_line() + 
  geom_linerange(aes(x = gr,
                     ymin = pct_rejected - 1.96*sd_rejected,
                     ymax = pct_rejected + 1.96*sd_rejected)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  guides(size = "none",
         colour = "none") +
  facet_wrap(~model) +
    labs(y = "Proportion Null Rejected",
       x = "Defier Proportion",
       caption = "Note: Point size indicates number of draws in bin. \n 95% Confidence Intervals Displayed.",
       title = "Power As a Function of Defier Proportion")

```



```{r}

library(ggridges)


sim_bin %>% 
  na.omit() %>% 
  ggplot(aes(x = pval_defier, y = gr, fill = gr)) +
  geom_density_ridges() +
  theme_ridges() +
  guides(fill = "none") +
  scale_x_continuous(trans = negative_log_trans(10)) +
  labs(y = "Defier Proportion",
       x = "P-Value",
       title = "P-Value distribution as Defier Proportion Changes",
       caption = "Note: X-Axis on negative log(10) scale.")




```


# References


