---
title: "Detecting Defiers: An Empirical Investigation"
author: "Ed Jee"
date: "22 January 2019"
output:
    html_document:
      code_folding: show
      highlight: tango
      theme: journal
      toc: yes
      toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

# Data and Replication
## Angrist and Evans 1998
#### 1990 Census Data
```{r data_import}
library(haven)
library(dplyr)
library(broom)
df_90 <- read_sas("AngEv98/AngEv98/m_d_903.sas7bdat")
```


Cleaning data according to Angrist and Evans SAS replication codes:
```{r data_cleaning}

clean_angrist_evans_data <- function(dataset){
  df_clean <- dataset %>% 
    filter((AGEM <= 35) & (AGEM >= 21)) %>% 
    filter(KIDCOUNT >= 2) %>% 
    filter(AGE2NDK >= 1) %>% 
    filter(AAGE == "0" & AAGE2ND == "0" & ASEX == "0" & ASEX2ND == "0") %>% 
    mutate(SEXK = as.numeric(SEXK),
           SEX2NDK = as.numeric(SEX2NDK),
           WEEK89D = as.numeric(WEEK89D),
           WEEK89M = as.numeric(WEEK89M),
           FERTIL = as.numeric(FERTIL)) %>% 
    mutate(fertdif = as.numeric(KIDCOUNT) - (FERTIL - 1),
           agefstm = as.numeric(AGEM) - as.numeric(AGEK)) %>% 
    filter(agefstm >= 15) %>% 
    filter(PWGTM1 > 0) %>% 
    mutate(samesex = (SEXK == SEX2NDK),
           morekids = (KIDCOUNT > 2)) %>% 
    rename_all(tolower)
  return(df_clean)
}
df_90_clean <- df_90 %>%
  clean_angrist_evans_data()

rm(df_90)
```

#### 1980 Census Data


```{r cleaning_1980}

df_80 <- read_sas("AngEv98/AngEv98/m_d_806.sas7bdat")

df_80_clean <- df_80 %>%
    mutate(SEXK = as.numeric(SEXK),
         SEX2ND = as.numeric(SEX2ND),
         WEEKSD = as.numeric(WEEKSD),
         WEEKSM = as.numeric(WEEKSM),
         YOBM = as.numeric(YOBM),
         AGEQK = as.numeric(AGEQK),
         YOBD = 80 - as.numeric(AGED),
         YOBD = ifelse(QTRBTHD == 0, YOBD, YOBD - 1)) %>% 
  mutate(samesex = (SEXK == SEX2ND),
         morekids = (KIDCOUNT > 2),
         ageqm = 4*(80-YOBM) - as.numeric(QTRBTHM) - 1,
         ageqd = 4*(80 - YOBD) - as.numeric(QTRBKID),
         agefstm = round((ageqm-AGEQK)/4),
         agefstd = round((ageqd - AGEQK)/4),
         QTRMAR = as.numeric(QTRMAR),
         QTRBTHM = as.numeric(QTRBTHM),
         AGEMAR = as.numeric(AGEMAR),
         QTRBKID = as.numeric(QTRBKID),
         FERTIL = as.numeric(FERT),
         ) %>% 
  rename_all(tolower)




df_80_filtered <- df_80_clean %>% 
  filter((agem <= 35) & (agem >= 21)) %>% 
  filter(kidcount >= 2) %>%
  filter(ageq2nd > 4) %>% 
  filter(agefstm >= 15) %>%
  filter(agefstd >= 15 | is.na(agefstd)) %>%
  filter(asex == 0 &
         aage == 0 & 
         aqtrbrth == 0 &
         asex2nd == 0 &
         aage2nd == 0 &
         aqtrbrth == 0)



df_80_filtered_two <- df_80_filtered %>% 
  mutate(
         qtrmar = ifelse(qtrmar > 0, qtrmar - 1, qtrmar),
         yom = ifelse(qtrbthm <= qtrmar, yobm + agemar, yobm+agemar+1),
         dom_q = yom + (qtrmar/4),
         do1b_q = yobk + qtrbkid/4,
         illegit = ifelse(dom_q - do1b_q > 0, 1, 0)
         ) %>%  
  mutate(
         msample = ifelse(
           !is.na(aged) &
           timesmar == 1 &
           marital == 0 &
           illegit == 0 &
           agefstd >= 15 &
           agefstm >= 15,
           1, 0)
         ) %>% 
  filter(msample == 1)

######################

df_80_subset <- df_80_filtered_two %>% 
  rename(kid_age = agek,
         m_age = agem,
         d_age = aged) %>% 
  select(-starts_with("a")) %>% 
  mutate_at(c("racek",
              "birthplk",
              "schoolk",
              "state",
              "spanishm",
              "spanishd",
              "poverty"), factor) %>% 
  mutate_if(is.character, as.numeric)



df_80_final <- df_80_subset %>% 
  mutate(boy1st = (sexk == 0),
         boy2nd = (sex2nd == 0),
         boys2 = (sexk == 0) & (sex2nd == 0),
         girls2 = (sexk == 1) & (sex2nd == 1),
         samesex = boys2 | girls2,
         morekids = kidcount > 2,
         black_m = (racem == 2),
         hisp_m = (racem == 12),
         white_m = (racem == 01),
         other_race_m = 1 - black_m - hisp_m - white_m,
         black_d = (raced == 2),
         hisp_d = (raced == 12),
         white_d = (raced == 1),
         other_race_d = 1 - black_d - hisp_d - white_d,
         worked_m = (weeksm > 0),
         worked_d = (weeksd > 0),
         income_m = 2.099173554*(income1m + pmax(0, income2m)),
         income_d = (income1d + pmax(0, income2d)),
         fam_inc = pmax(faminc*2.099173554, 1),
         nonmoi = fam_inc - income1m*2.099173554,
         nonmomil = log(pmax(1, nonmoi)))
rm(df_80,
   df_80_clean,
   df_80_filtered,
   df_80_filtered_two,
   df_80_subset)

```



## Replicating Results

```{r data_transforming}

transform_clean_angrist_evans <- function(dataset) {
  transformed_df <- dataset %>%
    rename(
      kid_age = agek,
      kid2_age = age2ndk,
      m_age = agem,
      d_age = aged
    ) %>%
    select(-starts_with("a")) %>%
    mutate_at(c(
      "racek",
      "birthplk",
      "schoolk",
      "state",
      "hispm",
      "hispd",
      "poverty",
      "pobm",
      "hispd",
      "pobd",
      "hispk"
    ), factor) %>%
    mutate_if(is.character, as.numeric) %>%
    mutate(
      boy1st = (sexk == 0),
      boy2nd = (sex2ndk == 0),
      boys2 = (sexk == 0) & (sex2ndk == 0),
      girls2 = (sexk == 1) & (sex2ndk == 1),
      samesex = boys2 | girls2,
      morekids = kidcount > 2,
      black_m = (racem == 2),
      hisp_m = (racem == 12),
      white_m = (racem == 01),
      other_race_m = 1 - black_m - hisp_m - white_m,
      black_d = (raced == 2),
      hisp_d = (raced == 12),
      white_d = (raced == 1),
      other_race_d = 1 - black_d - hisp_d - white_d,
      worked_m = (week89m > 0),
      worked_d = (week89d > 0)
    )

  return(transformed_df)
}

df_90_subset <- df_90_clean %>%
  transform_clean_angrist_evans()

  
  
  
df_90_final <- df_90_subset %>% 
  mutate(
         income_m = 1.2883*(incomem1 + pmax(0, incomem2)),
         income_d = (incomed1 + pmax(0, incomed2)),
         fam_inc = pmax(faminc*1.2883, 1),
         nonmoi = fam_inc - incomem1*1.2883,
         nonmomil = log(pmax(1, nonmoi))
  )

rm(df_90_clean, df_90_subset)
```


#### Table Two Summary Statistics

Trying to recreate table 2
```{r table_2}
library(tidyr)
AE_90_summary <- df_90_final %>% 
  summarise(children_ever_born = mean(fertil - 1),
            more_than_2 = mean(morekids),
            mean_boy_first = mean(boy1st),
            boy_2nd = mean(boy2nd),
            two_boys = mean(boys2),
            two_girls = mean(girls2),
            samesex = mean(samesex),
            age = mean(m_age),
            worked = mean(worked_m),
            weeks = mean(week89m),
            hrs_wk = mean(hour89m),
            labour_income_mum = mean(income_m),
            labour_income_dad = mean(income_d, na.rm = TRUE),
            fam_income = mean(fam_inc),
            mean_non_wife = mean(nonmoi)) %>% 
  gather(term, mean_90) 

AE_80_summary <- df_80_final %>% 
    summarise(children_ever_born = mean(fertil - 1),
            more_than_2 = mean(morekids),
            mean_boy_first = mean(boy1st),
            boy_2nd = mean(boy2nd),
            two_boys = mean(boys2),
            two_girls = mean(girls2),
            samesex = mean(samesex),
            age = mean(m_age),
            worked = mean(worked_m),
            weeks = mean(weeksm),
            hrs_wk = mean(hoursm),
            labour_income_mum = mean(income_m),
            labour_income_dad = mean(income_d, na.rm = TRUE),
            fam_income = mean(fam_inc),
            mean_non_wife = mean(nonmoi)) %>% 
  gather(term, mean_80) 

AE_summary <- inner_join(AE_80_summary, AE_90_summary, by = "term") %>% 
  knitr::kable(digits = 3)
AE_summary

```

#### Regression Results

Recreating Table 5
```{r table_5, results = "asis"}
library(AER)
library(stargazer)
library(purrr)
table_5_models_90 <- c("worked_m",
  "week89m",
  "hour89m",
  "income_m",
  "log(fam_inc)") %>%
  map(~(
  paste0(., " ~ morekids | samesex") %>% 
  as.formula() %>% 
  ivreg(., data = df_90_final)))

table_5_models_80 <- c("worked_m",
  "weeksm",
  "hoursm",
  "income_m",
  "log(fam_inc)") %>% 
  map(~(
  paste0(., " ~ morekids | samesex") %>% 
  as.formula() %>% 
  ivreg(., data = df_80_final)))

stargazer(table_5_models_80,
          omit = "Constant",
          title = "WALD ESTIMATES OF LABOR-SUPPLY MODELS 1980 DATA - REPLICATED",header = FALSE,type = "html",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"))

stargazer(table_5_models_90,
          omit = "Constant",
          title = "WALD ESTIMATES OF LABOR-SUPPLY MODELS 1990 DATA - REPLICATED",header = FALSE,type = "html",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"))





rm(table_5_models_80,
   table_5_models_90)
``` 



Now table 6
```{r table_6, results = "asis"}
library(purrr)
create_model_formula <- function(dependent_var){
  model <- as.formula(paste0(dependent_var, "~ morekids + m_age + boy1st + boy2nd + black_m + hisp_m + other_race_m | samesex +  m_age + boy1st + boy2nd + black_m + hisp_m + other_race_m"))
  return(model)
}

table_6_models_80 <- c("worked_m",
  "weeksm",
  "hoursm",
  "income_m",
  "log(fam_inc)") %>% 
  map(~(create_model_formula(.) %>% 
          ivreg(data = df_80_final)))
  

table_6_models_90 <- c("worked_m",
                    "week89m",
                    "hour89m",
                    "income_m",
                    "log(fam_inc)") %>% 
  map(~(create_model_formula(.) %>% 
          ivreg(data = df_90_final)))

stargazer(table_6_models_80,
          keep = "morekidsTRUE",
          title = "2SLS ESTIMATES OF LABOR-SUPPLY MODELS USING 1980 CENSUS DATA - REPLICATION",
          notes = "Age at first birth omitted since I can't seem to find it.",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"),
          type = "html")

stargazer(table_6_models_90, keep = "morekidsTRUE",
          title = "2SLS ESTIMATES OF LABOR-SUPPLY MODELS USING 1990 CENSUS DATA - REPLICATION",
          notes = "Age at first birth omitted since I can't seem to find it.",
          dep.var.labels = c("Worked",
                            "Weeks",
                            "Hours",
                            "Income",
                            "Family Income"),
          type = "html")
rm(table_6_models_80, table_6_models_90)
```



## Maimonides Rule


Mention somewhere HAC instead of moulton factor adjustment - only makes a large difference in the discontinuity sample.

#### Cleaning Grade 5
```{r maimonides_grade_5}
clean_maimonides_data <- function(dataset){
  clean_df <- dataset %>%
    mutate(
      avgverb = ifelse(avgverb > 100, avgverb - 100, avgverb),
      avgmath = ifelse(avgmath > 100, avgmath - 100, avgmath),
      func1 = c_size/(as.integer((c_size-1)/40)+1),
      func2 = cohsize/(as.integer(cohsize/40)+1),
      avgverb = ifelse(verbsize == 0, NA, avgverb),
      passverb = ifelse(verbsize == 0, NA, passverb),
      avgmath = ifelse(mathsize == 0, NA, avgmath),
      passmath = ifelse(mathsize == 0, NA, avgmath),
      disc = (c_size >= 36 & c_size <= 45) | 
             (c_size >= 76 & c_size <= 85) |
             (c_size >= 116 & c_size <= 125),
      all = 1,
      c_size_squared = (c_size^2)/100,
      trend = ifelse(c_size >= 0 & c_size <= 40, c_size, NA),
      trend = ifelse(c_size >= 41 & c_size <= 80, 20 + (c_size/2), trend),
      trend = ifelse(c_size >= 81 & c_size <= 120, (100/3) + (c_size/3), trend),
      trend = ifelse(c_size >= 121 & c_size <= 160, (130/3) + (c_size/4), trend)
    ) %>% 
    filter(
      classize > 1 & classize < 45 & c_size > 5
    ) %>% 
    filter(
      c_leom == 1 & c_pik < 3
    )
  return(clean_df)
  
}
df_final5_cleaned <- read_dta("Maimonides/final5.dta") %>% 
  clean_maimonides_data()

##do stuff


```


#### Cleaning Grade 4
```{r maimonides_grade_4}
df_final4_cleaned <- read_dta("Maimonides/final4.dta") %>% 
  clean_maimonides_data()

```


## Replicating OLS 
```{r replicating_maimonides, results = "asis"}
## Grade 5
col_1 <- lm(avgverb ~ classize, data = df_final5_cleaned)
col_2 <- lm(avgverb ~ classize + tipuach, data = df_final5_cleaned)
col_3 <- lm(avgverb ~ classize + tipuach + c_size, data = df_final5_cleaned)
col_4 <- lm(avgmath ~ classize, data = df_final5_cleaned)
col_5 <- lm(avgmath ~ classize + tipuach, data = df_final5_cleaned)
col_6 <- lm(avgmath ~ classize + tipuach + c_size, data = df_final5_cleaned)
## Grade 4
col_7 <- lm(avgverb ~ classize, data = df_final4_cleaned)
col_8 <- lm(avgverb ~ classize + tipuach, data = df_final4_cleaned)
col_9 <- lm(avgverb ~ classize + tipuach + c_size, data = df_final4_cleaned)
col_10 <- lm(avgmath ~ classize, data = df_final4_cleaned)
col_11 <- lm(avgmath ~ classize + tipuach, data = df_final4_cleaned)
col_12 <- lm(avgmath ~ classize + tipuach + c_size, data = df_final4_cleaned)

SEs <- list(col_1,
            col_2,
            col_3,
            col_4,
            col_5,
            col_6,
            col_7,
            col_8,
            col_9,
            col_10,
            col_11,
            col_12) %>% 
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))

stargazer(col_1,
          col_2,
          col_3,
          col_4,
          col_5,
          col_6,
          col_7,
          col_8,
          col_9,
          col_10,
          col_11,
          col_12,
          se = SEs,
          omit.table.layout = "sn",
          type = "html",
          omit = "Constant",
          dep.var.labels = c("English Comprehension",
                             "Maths",
                             "English Comprehension",
                             "Maths"),
          column.labels = c("Grade 5",
                            "Grade 4"),
          column.separate = c(6, 6),
          initial.zero = FALSE,
          notes = "HAC standard errors used instead of Moulton factor adjustment.")
rm(col_1,
   col_2,
   col_3,
   col_4,
   col_5,
   col_6,
   col_7,
   col_8,
   col_9,
   col_10,
   col_11,
   col_12
   )
```


## Replicating IV
```{r maimonides_IV, results = "asis"}

## Grade 5


iv_maim_verb_full_5 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned)
iv_maim_math_full_5 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned)

iv_maim_verb_disc_5 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned %>% filter(disc == 1))
iv_maim_math_disc_5 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final5_cleaned %>% filter(disc == 1))


## Grade 4

iv_maim_verb_full_4 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned)
iv_maim_math_full_4 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned)

iv_maim_verb_disc_4 <- ivreg(avgverb ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned %>% filter(disc == 1))
iv_maim_math_disc_4 <- ivreg(avgmath ~ classize + tipuach + c_size + c_size_squared | func1 + tipuach + c_size + c_size_squared, data = df_final4_cleaned %>% filter(disc == 1))




SEs_IV_5 <- list(
  iv_maim_verb_full_5,
  iv_maim_math_full_5,
  iv_maim_verb_disc_5,
  iv_maim_math_disc_5
) %>%
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))
stargazer(iv_maim_verb_full_5,
          iv_maim_math_full_5,
          iv_maim_verb_disc_5,
          iv_maim_math_disc_5,
          se = SEs_IV_5,
          column.labels = c("Full Sample", "Discontinuity Sample"),
          column.separate = c(2, 2),
          type = "html",
          title = "IV Maimonides Rule Fifth Grade",
          notes = "HAC standard errors used instead of Moulton factor adjustment.")



SEs_IV_4 <- list(
  iv_maim_verb_full_4,
  iv_maim_math_full_4,
  iv_maim_verb_disc_4,
  iv_maim_math_disc_4
) %>%
  map(~(vcovHAC(.) %>% 
          diag() %>% 
          sqrt))
stargazer(iv_maim_verb_full_4,
          iv_maim_math_full_4,
          iv_maim_verb_disc_4,
          iv_maim_math_disc_4,
          se = SEs_IV_4,
          column.labels = c("Full Sample", "Discontinuity Sample"),
          column.separate = c(2, 2),
          type = "html",
          title = "IV Maimonides Rule Fourth Grade",
          notes = "HAC standard errors used instead of Moulton factor adjustment.")

rm(SEs_IV_4,
   SEs_IV_5,
   SEs,
   iv_maim_math_disc_4,
   iv_maim_math_full_4,
   iv_maim_verb_disc_4,
   iv_maim_verb_full_4,
   iv_maim_math_disc_5,
   iv_maim_math_full_5,
   iv_maim_verb_disc_5,
   iv_maim_verb_full_5)

```


# Checking First Stage
## Simulations

```{r first_stage_sims}
library(margins)
x <- rnorm(100) + 3
D <- rbinom(100, size = 1, 0.5)
y <- D*5*x + (1-D)*-5*x + 10 + rnorm(100)
df_sim <- tibble(y, x, D)
lm(y ~ x, data = df_sim) %>% summary()
D_yes <- lm(y ~ x, data = df_sim %>% filter(D == 1)) 
D_no <- lm(y ~ x, data = df_sim %>% filter(D ==0)) 
D_int <- lm(y ~ x  +D+ x*D, data = df_sim) 

head(dydx(data = df_sim, D_int, "x"))


df_sim_margins <- margins(data = df_sim, D_int, "x", unit_ses = TRUE) %>% 
  as_tibble() %>% 
  mutate(dydx_x_low = dydx_x  - 1.96*SE_dydx_x,
         dydx_high = dydx_x + 1.96*SE_dydx_x)
  
df_sim_margins %>% head()
rm(x,
   D,
   y,
   df_sim,
   D_yes,
   D_no,
   D_int,
   df_sim_margins)

```




```{r first_stage_functions}

##TODO: Propagate dydx to entire dataset?
library(Rfast)

find_SEs <- function(model_data_no_y, model_vcov, instrument){
  model_data_no_y <- model_data_no_y %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0("~", "instrument", "*."))
  
  model_matrix <- model_data_no_y %>% 
    mutate(instrument = 1) %>% 
    model.matrix(model_formula, data = .)
  
  gradient_matrix_kinda <- model_matrix %>%
    as_tibble() %>% 
    distinct() %>% 
  mutate_at(vars(-contains(":")), ~(. = 0)) %>% 
    mutate(instrument = 1) %>% 
  as.matrix()
  
  split_indices <- seq(from = 1, to = nrow(gradient_matrix_kinda), by = 10000) %>% 
    c(nrow(gradient_matrix_kinda))
  
  if (length(split_indices) < 3){
    vcov_dydx_intermediate <- Rfast::mat.mult(gradient_matrix_kinda, model_vcov)
    vcov_dydx <- Rfast::mat.mult(vcov_dydx_intermediate,
                                 Rfast::transpose(gradient_matrix_kinda))
    SE_dydx <- sqrt(diag(vcov_dydx))
    
  } else {
    baby_SE <- matrix(nrow = nrow(gradient_matrix_kinda), ncol = 1)
    for (i in 1:(length(split_indices)-1)){
      baby_matrix <- gradient_matrix_kinda[split_indices[[i]]:split_indices[[i+1]], ]
      print(paste0(split_indices[i],"to", split_indices[i+1]))
      
      baby_vcov <- Rfast::mat.mult(baby_matrix, model_vcov)
      baby_vcov <- Rfast::mat.mult(baby_vcov, Rfast::transpose(baby_matrix))
      baby_SE[split_indices[[i]]:split_indices[[i+1]], ] <- sqrt(diag(baby_vcov))
      i <- i + 1
    }
    SE_dydx <- baby_SE[, 1]
  }

  return(SE_dydx)
    
} 
run_first_stage_interactions_fast <- function(dataset, dependent_variable, instrument, weights = NULL){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula, weights = weights)
  degrees_freedom <- first_stage_fit$df.residual
  instrument_dummy_val <- dataset$instrument[1]
  
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    distinct() %>% 
    mutate(instrument = instrument_dummy_val)
  first_stage_margins <- dydx(model = first_stage_fit, data = dataset_unique, variable = "instrument") 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins$SE_dydx_instrument <- find_SEs(dataset_unique, vcov(first_stage_fit), instrument)
  
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom),
           pval_holm = p.adjust(pval_one_neg, method = "holm"))
  return(df_margins)
}


```


## Angrist and Evans
```{r run_first_stage_AE}

AE_data_80 <- df_80_final %>% 
  select(
    samesex,
    morekids,
    black_m,
    hisp_m,
    other_race_m,
    black_d,
    hisp_d,
    other_race_d,
    gradem,
    graded,
    m_age,
    d_age
  ) %>% 
  na.omit()

AE_data_90 <- df_90_final %>% 
  select(samesex,
         morekids,
         black_m,
         hisp_m,
         other_race_m,
         black_d,
         hisp_d,
         other_race_d,
         yearschm,
         yearschd, 
         m_age,
         d_age,
         pwgtm1,
         pwgtd1) %>% 
  na.omit()





first_stage_interactions_80 <- AE_data_80 %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "morekids",
                                    instrument = "samesex") %>% 
  mutate(dataset = "1980") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm,  dataset, dydx_lo, dydx_hi)
first_stage_interactions_90 <- AE_data_90 %>% 
  run_first_stage_interactions_fast(dataset = .,
                                   dependent_variable = "morekids",
                                   instrument = "samesex") %>% 
  mutate(dataset = "1990") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm, dataset, dydx_lo, dydx_hi)

first_stage_interactions_AE <- bind_rows(first_stage_interactions_90, first_stage_interactions_80) 



```


testing old stuff
```{r old_stuff, eval = FALSE, echo = FALSE}

run_first_stage_interactions_fast_slow_SE <- function(dataset, dependent_variable, instrument){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula)
  degrees_freedom <- first_stage_fit$df.residual
  dydx_margins <- dydx(data = dataset,
                       model = first_stage_fit,
                       variable = "instrument") %>% pull()
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    distinct() %>% 
    mutate(instrument = TRUE)
  first_stage_margins <- dydx(model = first_stage_fit, data = dataset_unique, variable = "instrument") 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins$SE_dydx_instrument <- find_SEs_slow(dataset_unique, vcov(first_stage_fit), instrument)
  
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom))
  return(df_margins)
}

find_SEs_slow <- function(model_data_no_y, model_vcov, instrument){
  model_data_no_y <- model_data_no_y %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0("~", "instrument", "*."))
  
  model_matrix <- model_data_no_y %>% 
    mutate(instrument = 1) %>% 
    model.matrix(model_formula, data = .)
  
  gradient_matrix_kinda <- model_matrix %>%
    as_tibble() %>% 
    distinct() %>% 
  mutate_at(vars(-contains(":")), ~(. = 0)) %>% 
    mutate(instrument = 1) %>% 
  as.matrix()
  
  vcov_dydx_intermediate <- Rfast::mat.mult(gradient_matrix_kinda, model_vcov)
  vcov_dydx <- Rfast::mat.mult(vcov_dydx_intermediate, Rfast::transpose(gradient_matrix_kinda))
  SE_dydx <- sqrt(diag(vcov_dydx))
  return(SE_dydx)
    
} 


run_first_stage_interactions_slow <- function(dataset, dependent_variable, instrument){
  dataset <- dataset %>% 
    rename("instrument" = instrument)
  model_formula <- as.formula(paste0(dependent_variable,  "~ ", "instrument", "*."))
  first_stage_fit <- lm(data = dataset, formula = model_formula)
  degrees_freedom <- first_stage_fit$df.residual
  dydx_margins <- dydx(data = dataset,
                       model = first_stage_fit,
                       variable = "instrument") %>% pull()
  dataset_unique <- dataset %>% 
    select(-dependent_variable, -instrument) %>% 
    distinct() %>% 
    mutate(instrument = TRUE)
  first_stage_margins <- margins(first_stage_fit, data = dataset_unique, variables = "instrument", unit_ses = TRUE) 
  df_margins <- bind_cols(first_stage_margins %>% 
                            select(contains("dydx")),
                          dataset_unique) %>% 
    as_tibble()
  df_margins <- df_margins %>% 
    mutate(dydx_lo = dydx_instrument - qt(0.975, degrees_freedom) * SE_dydx_instrument,
           dydx_hi = dydx_instrument + qt(0.975, degrees_freedom) * SE_dydx_instrument,
           t_stat = dydx_instrument/SE_dydx_instrument,
           pval_one_neg = pt(t_stat, degrees_freedom))
  return(df_margins)
}



test <- test_data %>% 
  run_first_stage_interactions_fast_slow_SE(dataset = ., 
                                    dependent_variable = "morekids",
                                    instrument = "samesex")

all_equal(first_stage_interactions, test)
```



```{r plotting_first_stage_interactions}
library(ggplot2)
library(scales)
first_stage_interactions_AE %>% 
  filter(pval_one_neg < 0.1 | pval_holm < 0.1)

first_stage_interactions_AE %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset, scales = "free")

first_stage_interactions_AE %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset, scales = "free")

first_stage_interactions_AE %>% 
  group_by(dataset) %>% 
  sample_n(10000) %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  facet_wrap(~dataset, scales = "free_x") +
  geom_hline(yintercept = 0, linetype = "longdash")


```



```{r plotting_interactions_two}
negative_log_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("negative_log-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}


first_stage_interactions_AE %>% 
  group_by(dataset) %>% 
  sample_n(10000) %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values First Stage Interactions",
       subtitle = "Negative Log(10) Scale") +
  facet_wrap(~dataset) +
  geom_hline(yintercept = 0.05, linetype = "longdash", alpha = 0.2)





```

## Maimonides Rule


```{r maim_FS}
first_stage_interactions_maim_5 <- df_final5_cleaned %>% 
  select(classize,
         tipuach,
         c_size,
         c_size_squared,
         func1) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "classize",
                                    instrument = "func1") %>% 
  mutate(dataset = "Fifth Grade") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm,  dataset, dydx_lo, dydx_hi)

first_stage_interactions_maim_4 <- df_final4_cleaned %>% 
  select(classize,
         tipuach,
         c_size,
         c_size_squared,
         func1) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                   dependent_variable = "classize",
                                   instrument = "func1") %>% 
  mutate(dataset = "Fourth Grade") %>% 
  select(dydx_instrument, SE_dydx_instrument, pval_one_neg, pval_holm, dataset, dydx_lo, dydx_hi)

first_stage_interactions_maimonides <- bind_rows(first_stage_interactions_maim_5, first_stage_interactions_maim_4) 
```



```{r maim_plot}

first_stage_interactions_maimonides %>% 
  filter(pval_one_neg < 0.1 | pval_holm < 0.1)

first_stage_interactions_maimonides %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset, scales = "free")

first_stage_interactions_maimonides %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset, scales = "free")

first_stage_interactions_maimonides %>% 
  group_by(dataset) %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  facet_wrap(~dataset, scales = "free_x") +
  geom_hline(yintercept = 0, linetype = "longdash")

first_stage_interactions_maimonides %>% 
  group_by(dataset) %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values First Stage Interactions",
       subtitle = "Negative Log(10) Scale") +
  facet_wrap(~dataset) +
  geom_hline(yintercept = 0.05, linetype = "longdash", alpha = 0.2)


```

## Autor Dorn Hansen

```{r adh_fs}
df_china <- read_dta("Autor Dorn Hansen/dta/workfile_china.dta")
first_stage_interactions_ADH_manu <- df_china %>% 
  select(d_sh_empl_mfg,
         d_tradeusch_pw,
         d_tradeotch_pw_lag,
         l_shind_manuf_cbp,
         starts_with("reg"),
         l_sh_popedu_c,
         l_sh_popfborn,
         l_sh_empl_f,
         l_sh_routine33,
         l_task_outsource,
         t2) %>% 
  run_first_stage_interactions_fast(dataset = .,
                                    dependent_variable = "d_tradeusch_pw",
                                    instrument = "d_tradeotch_pw_lag",
                                    weights = df_china$timepwt48) %>% 
  mutate(dataset = "only")


```



```{r ADH_plot}
first_stage_interactions_ADH_manu %>% nrow()

first_stage_interactions_ADH_manu %>% 
  filter(pval_holm < 0.05)

first_stage_interactions_ADH_manu %>% 
  ggplot(aes(x = dydx_instrument, fill = dataset)) +
  geom_histogram() 

first_stage_interactions_ADH_manu %>% 
  ggplot(aes(x = pval_one_neg, fill = dataset)) +
  geom_histogram() 

first_stage_interactions_ADH_manu %>% 
  arrange(dydx_instrument) %>% 
  mutate(rank = row_number()) %>% 
  ggplot(aes(x = rank, y = dydx_instrument, ymin = dydx_lo, ymax = dydx_hi)) +
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.2) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash")

first_stage_interactions_ADH_manu %>% 
  ggplot(aes(sample = pval_one_neg, colour = dataset)) +
  stat_qq(distribution = qunif) +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  labs(title = "QQ plot of P-values First Stage Interactions",
       subtitle = "Negative Log(10) Scale") +
  geom_hline(yintercept = 0.05, linetype = "longdash", alpha = 0.2)
```


# Random Forest
## Angrist and Evans

```{r random_forest_run}
library(grf)
N_obs <- 10000
df_rf_AE_80 <- AE_data_80 %>% 
  sample_n(N_obs)

X_matrix_AE_80 <- df_rf_AE_80 %>% 
  select(-samesex, -morekids) %>% 
  as.matrix()

forest_first_stage_AE_80 <- causal_forest(X = X_matrix_AE_80,
                                    Y = df_rf_AE_80$morekids,
                                    W = df_rf_AE_80$samesex,
                                    num.trees = 4000) 
tau_hat_oob_AE_80 <- predict(forest_first_stage_AE_80, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "1980")

## Now 90s

df_rf_AE_90 <- AE_data_90 %>% 
  sample_n(N_obs)

X_matrix_AE_90 <- df_rf_AE_90 %>% 
  select(-samesex, -morekids) %>% 
  as.matrix()

forest_first_stage_AE_90 <- causal_forest(X = X_matrix_AE_90,
                                          Y = df_rf_AE_90$morekids,
                                          W = df_rf_AE_80$samesex,
                                          num.trees = 4000)
tau_hat_oob_AE_90 <- predict(forest_first_stage_AE_90, estimate.variance = TRUE) %>% 
  as_tibble() %>% 
  mutate(dataset = "1990")

tau_hat_oob_AE <- bind_rows(tau_hat_oob_AE_90,
                            tau_hat_oob_AE_80)


```

```{r random_forest_plots}


ggplot(tau_hat_oob_AE,
       aes(x = predictions,
           fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset)

tau_hat_results <- tau_hat_oob_AE %>%
  group_by(dataset) %>% 
  arrange(predictions) %>% 
  mutate(sigma_hat = sqrt(variance.estimates),
         prediction_lo = predictions - 1.96*sigma_hat,
         prediction_hi = predictions + 1.96*sigma_hat,
         t_stat = predictions / sigma_hat,
         critical_value = qt(0.95, N_obs - 13, lower.tail = FALSE),
         pval = pt(t_stat, df = N_obs - 13),
         pval_holm = p.adjust(pval, method = "holm"),
         reject_H0 = ifelse(pval_holm < 0.05, 1, 0),
         rank = row_number())

tau_hat_results %>% 
  ggplot(aes(x = rank, y = predictions, ymin = prediction_lo, ymax = prediction_hi)) + 
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.1) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  facet_wrap(~dataset) 

tau_hat_results %>% 
  filter(reject_H0 == 1) 


tau_hat_results %>% 
  ggplot(aes(sample = pval, colour = dataset)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  geom_hline(yintercept = 0.05, linetype = "longdash", alpha = 0.2) +
  labs(title = "QQ plot of P-values",
       subtitle = "Negative Log(10) Scale") +
  facet_wrap(~dataset)
  
```


## Maimonides Rule



```{r rf_run_maimonides}

X_matrix_maim_5 <- df_final5_cleaned %>% 
  select(
         tipuach,
         c_size,
         c_size_squared) %>% 
  as.matrix()

forest_first_stage_maim_5 <- causal_forest(X = X_matrix_maim_5,
                                    Y = df_final5_cleaned$classize,
                                    W = df_final5_cleaned$func1,
                                    num.trees = 4000) 
tau_hat_oob_maim_5 <- predict(forest_first_stage_maim_5, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "Fifth Grade")

## Now fourth grade


X_matrix_maim_4 <- df_final4_cleaned %>% 
  select(
         tipuach,
         c_size,
         c_size_squared) %>% 
  as.matrix()

forest_first_stage_maim_4 <- causal_forest(X = X_matrix_maim_4,
                                    Y = df_final4_cleaned$classize,
                                    W = df_final4_cleaned$func1,
                                    num.trees = 4000) 
tau_hat_oob_maim_4 <- predict(forest_first_stage_maim_4, estimate.variance = TRUE) %>%
  as_tibble() %>% 
  mutate(dataset = "Fourth Grade")


tau_hat_oob_maimonides <- bind_rows(tau_hat_oob_maim_5,
                                    tau_hat_oob_maim_4)
```



```{r rf_plot_maimonides}
ggplot(tau_hat_oob_maimonides,
       aes(x = predictions,
           fill = dataset)) +
  geom_histogram() +
  facet_wrap(~dataset)

tau_hat_results_maimonides <- tau_hat_oob_maimonides %>%
  group_by(dataset) %>% 
  arrange(predictions) %>% 
  mutate(sigma_hat = sqrt(variance.estimates),
         prediction_lo = predictions - 1.96*sigma_hat,
         prediction_hi = predictions + 1.96*sigma_hat,
         t_stat = predictions / sigma_hat,
         critical_value = qt(0.95, N_obs - 13, lower.tail = FALSE),
         pval = pt(t_stat, df = N_obs - 13),
         pval_holm = p.adjust(pval, method = "holm"),
         reject_H0 = ifelse(pval_holm < 0.05, 1, 0),
         rank = row_number())

tau_hat_results_maimonides %>% 
  ggplot(aes(x = rank, y = predictions, ymin = prediction_lo, ymax = prediction_hi)) + 
  geom_point(aes(colour = dataset)) +
  geom_ribbon(alpha = 0.1) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "longdash") +
  facet_wrap(~dataset) 

tau_hat_results_maimonides %>% 
  filter(reject_H0 == 1) 


tau_hat_results_maimonides %>% 
  ggplot(aes(sample = pval, colour = dataset)) +
  stat_qq(distribution = qunif)  +
  geom_abline(intercept = 0, slope = 1) +
  theme_minimal() +
  scale_x_continuous(trans=negative_log_trans(10)) +
  scale_y_continuous(trans=negative_log_trans(10)) +
  geom_hline(yintercept = 0.05, linetype = "longdash", alpha = 0.2) +
  labs(title = "QQ plot of P-values",
       subtitle = "Negative Log(10) Scale") +
  facet_wrap(~dataset)
```


